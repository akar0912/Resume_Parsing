{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import nltk\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "#from nltk.corpus import stopwords\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "matcher=Matcher(nlp.vocab)\n",
    "import PyPDF2\n",
    "from pywintypes import com_error\n",
    "import win32com.client as win32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(path):\n",
    "    with open(path+filename, 'rb') as fh:\n",
    "        # iterate over all pages of PDF document\n",
    "        for page in PDFPage.get_pages(fh, caching=True, check_extractable=True):\n",
    "            # creating a resoure manager\n",
    "            resource_manager = PDFResourceManager()\n",
    "            \n",
    "            # create a file handle\n",
    "            fake_file_handle = io.StringIO()\n",
    "            \n",
    "            # creating a text converter object\n",
    "            converter = TextConverter(\n",
    "                                resource_manager, \n",
    "                                fake_file_handle, \n",
    "                                codec='utf-8', \n",
    "                                laparams=LAParams()\n",
    "                        )\n",
    "\n",
    "            # creating a page interpreter\n",
    "            page_interpreter = PDFPageInterpreter(\n",
    "                                resource_manager, \n",
    "                                converter\n",
    "                            )\n",
    "\n",
    "            # process current page\n",
    "            page_interpreter.process_page(page)\n",
    "            \n",
    "            # extract text\n",
    "            text = fake_file_handle.getvalue()\n",
    "            yield text\n",
    "\n",
    "            # close open handles\n",
    "            converter.close()\n",
    "            fake_file_handle.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ashis_3yr_Infosys.pdf\n",
      "[' 5/27/2019\\n\\nASHIS\\xa0\\nPANDA\\nDATA ANALYST\\n ashisk.akp@gmail.com\\n\\n +917358270790\\n ashiskumarpanda\\n\\n\\uf0e0\\n\\uf0ac\\nhttps://medium.com/@GeneAshis\\n\\uf095\\n\\uf099\\n\\uf0e1\\nhttps://www.linkedin.com/in/ashis-\\npanda-b211b592/\\n CaptainAshis\\n\\uf09b\\nSummary\\n\\nData Scientist with 3+\\nyears of Experience\\nexecuting data-driven\\nsolution to increase\\ne\\x00ciency and accuracy.\\nExperienced in creating\\nmachine learning models\\nusing predictive data\\nmodelling techniques and\\nanalyzing the output of the\\nalgorithm to deliver\\ninsights and\\xa0 implement\\naction oriented solutions\\nto complex business\\nproblems.\\n\\nSkills\\n\\nPYTHON\\n\\nSQL\\n\\nR\\n\\nDATA SCIENCE\\n\\nMACHINE LEARNING\\nALGORITHMS\\n\\nTABLEAU\\n\\nPYTORCH\\n\\nKERAS\\n\\nMATPLOTLIB\\n\\nNUMPY\\n\\nPANDAS\\n\\nDEEP LEARNING\\n\\nSCIKIT LEARN\\n\\nhttps://resume.creddle.io\\n\\nEducation\\n\\nCreddle | Resume\\n\\nBachelor Of Technology in Electrical and Electronics Engineering at Vellore\\nInstitute of Technology , India\\n\\n2011 to\\n2015\\n\\nEmployment\\n\\nInfosys\\nAnalyst\\n\\nProjects\\n\\nBangalore\\nDec. 2015 to Current\\n\\nDeveloped the Dynamic pricing module for one of the largest Logistics Company in USA\\nOur Client is a Freight company who acts as a broker between Clients who wants their loads to\\nbe transported and Truckers.\\nThey would get a quotation\\xa0 price by their Clients for the load to be transported and would\\nnegotiate that amount with truckers. This was basically done by the Carrier Representatives in\\nour Client company by using their existing domain knowledge and their years of experience in\\nnegotiating.\\nOur main aim was to develop a dynamic pricing model which understands that given the factors\\ninvolved, it can exactly come up with a price that has to be paid to the truckers. Responsibilities\\nundertaken as a part of this project :-\\ni) Developed the conceptual and analytical framework of the proposal, as well as the codes for\\nthe algorithm used for analysis.\\xa0\\nii) Implemented various ML model for all the lanes and the data was sequenced temporally.\\xa0\\niii) Used Random Forest , XgBoost , Ridge and Lasso models and took an ensemble approach on\\ntop of these models, to come up with the best model.\\niv) Worked directly on the client presentation as well as presented it to the client for the pitch.\\nv) Trained other team members on the tools and techniques used for developing the Ensemble\\nmodel.\\n\\nRecommendation System\\nI developed a Recommendation system using Neural Network.\\n1. A recommendation system, in general consists of a User and an Item.\\n2. Each user and each Item were randomly initialized with a set of random numbers also known\\nas Entity Embedding. These embeddings were passed as an input to a Neural Network and it\\ngets updated as we train our Neural Network.\\n3. At the end of our training, it’s found that the User and Movie embedding which were random\\nvalues initially, has been updated during the training phase and these values starts making\\nsense. These updated set of numbers represents the genre of Movies and the Preference of\\nUsers.\\n4.\\xa0 Using these updated Entity Embedding a Recommendation system was developed.\\n\\nActivities\\n\\nTowards Data Science and Hackernoon publication. · Writer\\nI work with Towards Data Science and Hackernoon publication as a Technical Writer. These are\\nthe biggest Machine Learning publication with an outreach of more than 100k subscribers.\\nA couple of my blogs have received good appreciation from eminent deep learning personalities\\nlike Jeremy Howard (Deep Learning Researcher , President of Kaggle) and David Robinson (Chief\\nData Scientist at Datacamp) .\\xa0\\n\\n2018 to Current\\n\\nYes Bank · Guest Blogger\\nYesBank selected my blog to cover about their mega Datathon event held at Bangalore.  \\n\\nAnalytics Society Meetup\\nI am a part of Analytics Society Meetup at my workplace. My responsibilities involve\\nbrainstorming concepts of Deep Learning and making the participants understand my\\nexperience of solving a project using Deep Learning approach. \\n\\nGuest Lecture at Praxis Business School, Bangalore · \\nI was invited for a session on Deep Learning at Praxis Business School, Bangalore .\\n\\n1/1\\n\\n\\x0c']\n",
      "Ayan_cv_pdf.pdf\n",
      "['    AYAN MAZUMDER \\n\\n \\n\\n \\n\\n \\n\\n          mazuayan@gmail.com \\n\\nContact No: 7829657213                                          Current Location: Mumbai (open                     \\n\\nto reallocation)            \\n\\n----------------------------------------------------------------------------------------------------------------------------- ---------- \\n\\nFUNCTIONAL/TECHNICAL KNOWLEDGE: \\n\\n•  Skill Sets (Tools): SQL, R, Power BI, Qlikview, MS Excel, MS power point, SAS (base) \\n\\n \\n\\n•  Analytics Modules: Predictive modelling, logistic regression, linear regression, \\n\\nsegmentation, K means clustering, CLTV, campaign analytics, decision trees, CHAID, factor \\n\\nanalysis, market mix modelling, time series, forecasting, credit-risk, Data Science, retail \\n\\nanalytics, BFSI \\n\\n \\n\\nWORK EXPERIENCE \\n\\nSummary: Have over 36 months of analytics experience, implementing end to end analytics driven \\n\\nbusiness solutions for major Automotive, Retail, DTH and BFSI clients. \\n\\nTenure: \\n\\n-  Senior Business Analyst (Analytics) in Hansa Cequity Pvt. Ltd. (April 2019- till date)  \\n\\n-  Business Analyst (Analytics) in Hansa Cequity Pvt. Ltd.  (Nov 2016-March 2019) \\n\\n-  Analytics Analyst in ACCENTURE AI (CAMPUS HIRE) (Aug 2015- March 2016) \\n\\n \\n\\nPROFESSIONAL PROJECTS @ Hansa Cequity: \\n\\n \\n\\nSegmentation  of  Customer  Base  for  enriching  customer  experience  and  targeted \\n\\nmarketing for a leading automotive industry \\n\\n•  Performed an end to end value based customer segmentation to differentiate a high valued \\n\\ncustomer  from  a  middle  or  lower  valued  customer,  based  on  historical  transactions. \\n\\nMethodology included extensive data preparation/manipulation in SQL and implementing \\n\\nan unsupervised clustering algorithm in R to derive the final segments. \\n\\n•  Use Cases: Implemented these segments across all business touchpoints for differential \\n\\ncustomer  treatment  and  increasing  sales  through  precise  communications  and  targeted \\n\\nmarketing   \\n\\n   \\n\\n              \\n\\n\\x0c']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['          Calculating CLTV for a leading automotive industry \\n\\n•  Built  a  mathematical  algorithm  plugging  in  statistical  models  to  calculate  the  lifetime \\n\\nvalue(past+future) of a customer to understand his business value. \\n\\n•  Use Cases: Implemented CLTV scores across all business touchpoints to make impactful \\n\\nbusiness communications with the customers thereby increasing retention and sales. \\n\\n \\n\\n          Repurchase and Referral models for a leading automotive industry: \\n\\n \\n\\n•  Built  and  implemented  a  repurchase  model  (Logistic  regression  model)  to  track  down \\n\\ncustomers with a high propensity to repurchase/next purchase. \\n\\n•  Built and implemented a referral model (Logistic regression model) to identify customers \\n\\nwith a high propensity to refer. \\n\\n•  Benefits:  Significant  increase  in  loyalty/referral  sales  and  campaign  cost  optimization \\n\\nthrough precise marketing  \\n\\n \\n\\n           Lapsation and Revival Models for a leading Life Insurance client: \\n\\n \\n\\n•  Built and implemented separate logistic regression models to identify customers who are \\n\\nmost likely to lapse their policies and customers who are most likely to revive their \\n\\npolicies \\n\\n•  Benefits: Helps client to proactively design strategy to enhance value and retain \\n\\ncustomers. Sending campaigns to the right audience helps in cost optimization \\n\\n        \\n\\n     Churn Model for automotive, retail and DTH clients:  \\n\\n•  Built an end to end churn model (Logistic regression model) to track down customers with \\n\\na high propensity to churn \\n\\n•  Use Cases and Benefits: Sending customized campaigns to highly probable to churn \\n\\ncustomers to increase customer retention \\n\\n \\n\\nProjects @ Accenture: \\n\\n \\n\\n            Market Mix Modeling for A LEADING TELECOM COMPANY \\n\\n•  Scored Market Mix Models to find out the most efficient marketing source as in TV, Radio, \\n\\nNewspaper, Campaigns for optimizing advertising budget. \\n\\n\\x0c']\n",
      "['        Market Mix Model for a leading TOY MANUFACTURING COMPANY(retail): \\n\\n•  Measured the promotional uplifts as in the difference between baseline and actual sales \\nto find out the most effective promotional campaigns that were generating a higher lift in \\nsales \\n\\n \\n\\n                                                                  EDUCATION:   \\n\\n•  Masters in Economics from Jadavpur University, Kolkata (2015) - GPA  7.9   \\n\\n•  Bachelors in Economics from Jadavpur University, Kolkata (2013) - GPA  6.33  \\n\\n•  HSC/12th Higher Secondary from South Point High School, Kolkata (2009) – 71.8%   \\n\\n•  SSC/10th Madhyamik from South Point High School, Kolkata (2007) – 84.5%    \\n\\n \\n\\n                                                         NOTEWORTHY MILESTONES \\n\\n•  Consistently rated among the top performers over the last two Financial Years \\n\\n•  Won 6 quarterly awards at Hansa Cequity for excellence in performance \\n\\n•  Have  won  several  awards  for  acing  Table  Tennis  and  Swimming  competitions  in  both \\n\\ncollege and school \\n\\n \\n\\n \\n\\n \\n\\n         \\n\\n \\n\\n \\n\\n \\n\\n\\x0c']\n",
      "Copy of Pooja Resume Data_-2019.pdf\n",
      "[' Pooja Vishwakarma \\n\\n \\n\\nContact No: \\u200b91-7899632781;\\u200b Email: \\u200bPooja03july@gmail.com \\u200bLinekdln;\\u200bPooja vishwakarma \\n\\nManyata Tech Park.  560045 \\n\\n \\n\\nData Science & Automation Professional \\n\\nOffering 3.6 years of experience across Machine learning, Artificial Intelligence; Automation; Rest Services;R; Python; \\n\\nSeeking challenging assignments across Machine Learning, Artificial Intelligence & Data Analysis. \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nPROFILE \\n\\n \\n\\n \\n \\n✓ Equipped with the knowledge of various Analytical skills and machine learning & artificial\\n \\n\\nintelligence\\n \\ntechniques , sound understanding & skill of creating new software & systems, designing, analysis, testing,\\n \\n \\ndatabase development & coding for modules as per the requirements. \\n\\n✓ Possess knowledge of programming languages like C, C++, R, SQL, Python.  \\n✓ Good communication skills, verbal as well as written coupled with exceptional presentation skills with the\\n \\n\\n \\n \\n\\n \\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n✓ Focused individual with an analytic bent of mind and technical understanding coupled with creativity,\\n \\n\\n \\ncommunication, debugging and problem-solving skills and confident to take challenging assignments. \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\nability to perform above expectations. \\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nTECHNICAL \\u200bSKILLS \\n \\nProgramming Languages: \\u200bC, C++, R, SQL and Python. \\nTheoretical Concepts: \\u200bData Structures, Analysis and design of algorithm, Object Oriented programming \\nlanguage,Random Forest, Natural Language Processing, Artificial Neural Networks, Data base management, \\nOperating systems, Pattern recognition. \\nTools used: \\u200bR Studio, SQL server, MS Excel, MS Office, Anaconda,  \\nTechnical Training: \\u200bData Analysis using MS Excel and R and build the models using R & Python Languages. \\n \\nCurrent organization \\n \\nOrganization: \\u200bIBM india Pvt. Ltd.  \\nDivision: \\u200bIT \\nDesignation: \\u200bData scientist \\nDuration: \\u200bfeb 2016 till date \\n \\nProject1: \\u200bEnkana,sysco,Honda,Amul. \\nDescription: \\u200bDeveloped data Analysis skills based on using decision tree. \\n \\nProgramming Language Used: \\u200bPython, Rstudio,Cognos \\n \\n \\n\\nPAST EXPERIENCE \\n\\nOrganization\\u200b:\\u200bLoanshoppe \\nDivision\\u200b:\\u200bSecurity Analyst \\n \\nDesignation\\u200b:\\u200bSecurity and Risk management \\nDuration\\u200b:\\u200bjuly 2014 to july 2015 \\n\\n\\x0c']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['  \\n\\n \\n\\n \\n \\n\\n \\n\\nKey Deliverables \\n✓ Analyzing the patterns in the data,data validation health check. \\n\\nProjects Handled \\n\\nProject1: \\u200bGSNI \\n \\nDescription:  Da\\u200bta validation,Data Healthcheck,Missing Values \\n \\nProgramming Language Used: \\u200bUAT Tool,URT tool,Ms excel. \\n \\n\\xa0\\n \\n \\n\\nTechnical Area of Expertise \\n\\n✓ Building the solutions by having the thorough knowledge on business domain of the clients . \\n✓ Doing Literature survey to build Solutions to innovative ideas. \\n✓ Holding experience of Solutions, calculated fields, Notifications Reports, Advanced Work Flow, Data feed,\\n \\nAccess Control, Questionnaires, Sub forms, Data Import, Creating multiple layouts, Packaging, Analyzing data,\\n \\nData analysis and observe the patterns.  \\n\\n✓ Thorough Knowledge on Advance  MS Excel, R Language, Python, Rest Services, Data Analysis and Linux \\n\\n \\n \\n\\n \\n \\n\\n \\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nKey Deliverables \\n\\n✓ Analyzing the patterns of problems in the Data \\n✓ Literature survey to Choose better technique to solve Problem. \\n✓ Designing and developing the system Using R Language. \\n✓ Involve in requirement analysis, database design, coding, testing, implementation and maintenance of several\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nsoftware applications. \\n\\n \\n\\nProjects Handled \\n\\n● Description: \\n●\\n\\nProject1: \\u200bCredit Risk Modelling.(4 mos) \\nDescription: \\u200bWorked on a project related to Financial Markets wherein I had to examine the trust worthiness of a prospective customer and \\nhis/her possibility of defaulting on loan \\n \\nProgramming Language Used: \\u200bR language ,Python. \\n\\n \\n\\n \\n\\n\\u200bThe task was to build a Behavioural Credit Risk Model based on a large sample of data by applying\\n \\n \\nLogistic Regression. \\n● The data had various information related to behaviour transactional details of the customers and their\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nperformance in repayment. \\n\\n● There were number of validation checks which were performed to test the robustness of the model\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nunder taken in terms of various goodness–of–fit statistics.  \\n\\n● There were number of goodness of fit statistics which we had considered like Percent Concordant,\\n \\n\\n \\nHosmer – Lemeshow test, Wald – chi square and score tests. \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n \\n \\nProject2:  \\u200bENKANA (8 mos) \\n \\nDescription: \\u200bWorked on\\u200b \\u200ba project related to Server based Incident data,labeling,analysis \\n \\n\\n\\x0c']\n",
      "['  \\nProgramming Language Used: \\u200bR language, Sql, Machine learning \\n \\n\\n●\\n\\n●\\n\\n●\\n\\n●\\n\\n●\\n\\n \\n\\n \\n\\nThe task was to build cognos visualization based on our data analysis using graph. \\n\\nThe data had various information related to Pending activity, SLA due,Error in backside Information and \\nprediction on various variable dataset \\n\\nThere were number of validation checks which were performed to test the robustness of the model under \\ntaken in terms of various goodness–of–fit statistics. \\n \\n Worked on data consolidation, pre-processing, entity extraction, ticket classification, Dynamic dashboard \\ncreation and presentation with clients/TSM’s (Technical Solution Managers). Naïve Bayes classifier, KNN \\nclassifier, SVM classifier, Decision tree classifier and SVD with cosine similarity are some of the classification \\nalgorithms I worked on to classify IT tickets automatically. \\n\\n Outlier/Anomaly detection: Working on different outlier techniques like Inter quartile range, Normalized \\nZ-score,  PCA for outlier detection. Deploy our Project with watson and get feedback based on accuracy, \\n \\n\\n \\nProject3:  \\u200bHouse selling data Price Prediction.(4 mos) \\nProgramming Language Used: \\u200bPython \\n \\n\\n● Description: \\n●  \\u200bI have worked on House selling data Prediction via using different techniques,variable,Numerical and \\n\\ncategorical,data which is giving me final output using python\\u200b. \\n\\n● Natural  Language Processing (Text Minning) \\n● Working on Advanced text analytics which includes Pre-processing, clustering, cluster labellingand KB \\n\\n(knowledge base) document/information retrieval using different machine learningalgorithms.  \\n\\n● Data Pre-processing involves, standard & account specific stop word removal, Entity extraction (using \\n\\nregex or using predefined list–simple matching). K-means clustering, Connected components with \\nGraph & Affinity propagation are some of the clustering techniques I worked on to get clusters/groups \\nof similar issue tickets. Text Rank - A high frequency unigram based labeling & Two-level label \\ngeneration for document clusters using top keyword combinations. \\n\\n \\n\\n \\n \\n\\n✓ R installations and programming. \\n✓ Reading the research papers and applying those techniques to our problems \\n✓ Understanding the patterns in the raw data using R Language and MS Excel and building the potential\\n \\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nTechnical Area of Expertise \\n\\nSolutions for Problem. \\n\\n✓ Thorough Knowledge on MS Excel, Random forest, Data analysis and Machine learning concepts. \\n \\n \\n\\nACADEMIC CREDENTIALS \\n\\n \\n\\n \\nBachelors in Engineering; \\u200bTrinity institute  of Technology and Reserach, Rajiv Gandhi Technical \\nuniversity \\u200bSecured:\\u200b 7. 0Percentile \\nSpecialization:  \\u200bElectronics and communication \\n\\n\\x0c']\n",
      "['  \\n \\n\\n✓ Winner of Accenture hackathon 2017 globally. \\n✓ Performed best analytics Rating in Project globally. \\n✓ Got \\u200bProspera Techie\\u200b during the quarter Oct-Dec 2016 From \\u200bIBM.\\u200b. \\n \\n\\n \\n\\n \\n\\n \\n\\nDate of Birth: \\u200b3rdJuly, 1992;\\u200b Gender\\u200b:Female\\u200b;\\u200b Language Proficiency: \\u200bEnglish, German, Hindi; \\n\\nPERSONAL DETAILS \\n\\n\\x0c']\n",
      "DilipBehera_Resume.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Dilip Kumar Behera \\n\\n+91-8895471553 | E: dilipbehera003@gmail.com \\n\\n \\n\\nMahadevapura, Bangalore, Karnataka 560037 \\n\\nPROFESSIONAL \\n\\nSUMMARY \\n\\nSKILLS \\n\\nBusiness outcome oriented data scientist with 3.5 years of experience and a \\n\\nproven ability of delivering powerful business insights via data science \\n\\nmethodologies \\n\\n•  Python: \\n\\n•  Tableau:Tableau \\n\\nNumpy,Pandas,Matplotlib,Seaborn\\n\\nDesktop,Tableau Prep \\n\\n,Scikit-learn,NLTK \\n\\n•  Statistics \\n\\n•  Machine Learning Algorithms \\n\\n•  Advance Excel \\n\\nClassification, Regression, \\n\\nClustering, CART, Dimension \\n\\nReduction Techniques, NLP and \\n\\nEnsemble Methods \\n\\n•  SQL \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nWORK HISTORY \\n\\nDATA SCIENTIST  \\n\\n 10/2015 to CURRENT  \\n\\nEricsson India Global Services | Bengaluru, KA \\n\\n1.Project Summary :Sleeping Cell Predictions \\n\\n•  Build a classification model on given historical data to analyze the traffic on \\n\\nindividual node and predicted the sleeping nodes. \\n\\n•  Approach: Performed data preprocessing ,exploratory data analysis after \\n\\ngathering data from multiple BU .Applied Logistic regression,LDA, KNN \\n\\n,SVM and Random Forest Algorithms. \\n\\n2.Project Summary : Field Dispatch Prediction \\n\\n•  Built a classification model for the tickets with issue and predict whether \\n\\nthe ticket needs to be dispatched or not \\n\\n•  Approach:Performed data cleaning, Feature engineering and developed a \\n\\nclassifier using Bayes Theorem and NLTK package , also improved the \\n\\nperformance using ensemble method. \\n\\n3.Project Summary: KPI Analysis And Optimization \\n\\n•  Developed a model for predicting the network key performance Indicators \\n\\n(Accessibility, Retainability, Mobility, RSSI) for Sprint \\n\\n•  Approach:Performed exploratory data alalysis and then spot checked \\n\\nvarious regression algorithms such as linear regression ,Ridge regression \\n\\n,KNN ,Elastic net regression and SVM \\n\\n4.Project Summary: Dashboards and Reporting \\n\\n•  Reported insights gathered from models through Tableau across internal \\n\\nand external stakeholders. \\n\\n•  Created a customized dashboard for quick KPI check after parameters \\n\\nchanges which saved 2520 minutes yearly. \\n\\n\\x0c']\n",
      "[' EDUCATION \\n\\nACCOMPLISHMENTS \\n\\nHOBBIES \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n•  Ensured timely submission of Daily/Weekly/Monthly/Quarterly/Annual \\n\\nreports to respective stakeholders. \\n\\nB.Tech | Electronics And Telecommunications  \\n\\n2015  \\n\\nKalinga Institute of Industrial Technology, Bhubaneswar, OD \\n\\n•  Graduated with 8.02 CGPA \\n\\n•  Awarded Student Leader Medal for leading our college NCC group in the \\n\\nrepublic day parade. \\n\\n•  Named Appreciation from the Customer in Project Success Stories \\n\\nPublication \\n\\n•  Power Award for Q1, 2019  \\n\\n•  Ace Award for Q2 2018  \\n\\nBodybuilding and Motorcycling \\n\\n\\x0c']\n",
      "Kuntal RoyChowdhury_Resume.pdf\n",
      "['  \\n\\n \\n\\n \\n\\n \\n\\n     KUNTAL \\n\\n \\n\\n \\n\\n     ROY CHOWDHURY \\n\\n          Data Scientist \\n\\nPROFILE \\n\\n \\n\\nMicrosoft \\n\\nindustry.  Skilled \\n\\nExperienced  Senior  Associate  with \\nknowledge  of  time  series  analysis  in \\nautomotive \\nin  R \\nprogramming, \\nExcel, \\nMicrosoft  Word,  Data  Analysis, \\nStatistical  modelling  &  Data  Science. \\nStrong  professional  with  a  master’s \\ndegree \\nstatistics  and \\ncomputing \\nfrom  Banaras  Hindu \\nUniversity. \\n\\nfocused \\n\\nin \\n\\nCONTACT \\n\\n+91-9831464541 \\n\\nkroychowdhury121@gmail.com \\n\\nKolkata, India \\n\\nhttps://www.linkedin.com/in/kunt\\nal-roy-chowdhury-76a5b3135/ \\n\\nCERTIFICATION \\n\\nStatistics with R Specialization \\n\\n(MOOC by Duke university on Coursera) \\n\\nEXPERIENCE \\n\\nSENIOR ASSOCIATE | GENPACT    Jun,2018 - Present \\n\\n❖  I am working for a steel production management client- in \\nthe  automotive  sector,  doing  demand  forecasting  for  the \\nupcoming year. The main aim being reducing the inventory \\ncost  of  the  company.  This  particular  project,  required \\nforecasting for diverse data which sometimes fluctuated with \\nno normal trend. Hence it had to be treated in different ways. \\nI  have  successfully  created  several  models  in  R  software, \\nnamely  Ratio  to  Moving  Average,  Fourier  Transformation, \\nCroston,  Holt-winters  &  Double  Exponential  Each  model  is \\nused  to  deal  with  separate  types  of  data  altogether. \\nAutomating them in R has raised the quality of the outcome \\nof the forecast, reduced the time taken and  can be  further \\nused by the company evenly. \\n \\n\\n \\n\\n❖  I have also been generating a significant number of reports \\n\\non a daily basis by automating this process in R. This has \\nreduced manual error to a great extent and levelled up the \\nreport results. Moreover, it has helped save time and effort \\nsimultaneously. \\n \\n\\n❖  Furthermore, I have actively tried to integrate tableau and \\n\\nR, which has reduced the respective drawbacks of both the \\ntools. \\n\\nFreelance statistics consultant (Internship) \\n\\nTutor Help Desk | Feb,2018 – June,2018 \\n\\nI provide consultancy for educational projects requiring \\nstatistical analysis using R and SAS for the overseas \\nstudents. \\n\\n \\n\\nEDUCATION \\n\\n2018 \\n\\n2016 \\n\\nM.Sc. Statistics & Computing \\n\\nBanaras Hindu University | CGPA: 7.41/10 \\n\\nB.Sc. (Hons) Statistics \\n\\nUniversity of Calcutta| Percentage: 57.125% \\n\\nSKILLS \\n\\nR Programming Language and Environment (Proficient) \\n\\nTableau (Intermediate) \\n\\nLicense: WEZLK96UWP5R \\n\\nAdvanced Excel \\n\\n \\n\\n\\x0c']\n",
      "Megha_Resume.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" Megha Kumari\\n\\nGraduate Analyst\\nMotivated , team-work oriented , and responsible Data Analyst with signiﬁcant experience in translating numbers into\\nmeaningful facts for businesses to help them make better business decisions. Aiming to utilize my skills and experience\\nin predictive modelling , data processing , data mining , machine learning algorithms and strong analytical ability to solve\\nchallenging business problems.\\n\\nmeghak39@gmail.com\\n\\n8145736126\\n\\nPune, India\\n\\nlinkedin.com/in/megha-kumari-542726a1\\n\\nWORK EXPERIENCE\\nGraduate Analyst\\nBarclays\\n07/2018 – Present\\nAchievements\\n\\nSKILLS\\n\\nR programming\\n\\nPython\\n\\nMySQL\\n\\nPune, Maharashtra\\n\\nSAS\\n\\nTableau\\n\\nGroovy\\n\\nBuilt an analytics engine that makes use of activity logs across various digital channels\\nof Barclays and predict possible customer journeys across these channels.\\nFurther identiﬁed the customer journeys which failed or were abandoned and the\\npossible reasons associated with it to convert the data acquired into actionable\\ninsights.\\nBuilt a sentiment analysis tool using Natural language Processing which identiﬁed\\npositive as well as negative features of different digital channels by making use of NPS\\n(Net Promoter Score) and reviews given by customers.\\nJIRA AUTOMATION : Wrote groovy scripts to automate the task of creating an issue in\\nJira whenever any component of Barclays environment went down .\\n\\nData science Intern\\nadglobal360\\n05/2017 – 07/2017\\nAchievements\\n\\nGurugram, Haryana\\n\\nMaruti True Value Pricing engine : Built a prediction engine using ML techniques that\\npredicts a tentative purchasing price by evaluating different parameters of the pre-\\nowned cars.\\nUsed historical data to Train, Test and Reﬁne the model.\\nCarried out various steps such as : Data pre-processing , Model designing and building ,\\nModel Analysis and Reﬁnement, Model Testing and Model Validation with various\\ntechniques and algorithms using R programming.\\n\\nPERSONAL PROJECTS\\nSafety Analytics, IIT Kharagur (01/2017 – 04/2017)\\n\\nResearch and data collection of different causes of accidents and types of accidents.\\nUsed various algorithms such as MLR , SVM , KNN , CART to analyse their performance on safety\\ndata based on different kinds of accidents and their causes.\\nAnalysed and studied different safety measures to be taken at a plant.\\n\\nEDUCATION\\nBachelor of Technology\\nIndian Institute of Technology, Kharagpur\\n07/2014 – 04/2018\\n\\nSenior Secondary\\nChinmaya Vidyalaya\\n2012 – 2014\\n\\nSecondary\\nChinmaya Vidyalaya\\n2012 – 2011\\n\\n7.08 CGPA\\n\\n86%\\n\\n10 CGPA\\n\\nMachine Learning\\n\\nData mining\\n\\nData Processing\\n\\nTeamwork\\n\\nTeam Leadership\\n\\nC\\n\\nC++\\n\\nNoSQL\\n\\nHTML\\n\\nCSS\\n\\nPOSITION OF\\nRESPONSIBILITY\\nCore Team Member , Composit IIT Kharagpur\\n(2015 – 2017)\\n• Publicized the fest in various colleges of Jharkhand and\\nWest Bengal and achieved a YoY increase of 200% in the\\nparticipation • As a part of Corporate and Media Relations\\nTeam, was successful in bringing a total monetary amount of\\nINR 2 lacs for the fest • Managed the accommodation of over\\n350 participants and served as a contact point for\\ninformation dissemination • Conducted TECHNOVA, the\\nﬂagship event of COMPOSIT'16\\n\\nCampus Aﬃliate , Kshitij IIT Kharagpur\\n(2014 – 2015)\\n• Worked with a team for 20 people for the publicity and\\nground level execution of events in Kshitij 2015. •\\nResponsible for the in-house publicity of the online events of\\nKshitij 2015 among the 10,000 residents at the institute. •\\nPublicized in colleges of West Bengal and Jharkhand getting\\nthe highest ever participation from the respective regions •\\nLed the media campaign in Ranchi & responsible for 3 media\\narticles in leading newspapers of the region. • Involved in\\nGuest reception team during the fest\\n\\nSecretary Dramatics (2015 – 2016)\\nI was responsible for helping General Secretary ,Social and\\nCultural in organizing Dramatics events in hall when needed\\nand coordinated with hall boarders for active participation in\\nall Dramatics events at the inter hall level as well as open IIT\\nlevel.\\n\\nVOLUNTEER EXPERIENCE\\nStudents' Alumni Cell, IIT kharagpur\\n(2014 – 2015)\\nparticipated in the event PHONATHON wherein i personally\\ncontacted several alumni for institutes fundraising campaign\\n\\nNSO Health and Fitness IIT kharagpur\\nparticipated in Campus CLEANLINESS DRIVE organised by\\nNSO Health and Fitness.\\n\\n\\x0c\"]\n",
      "Shashikanth Kadam - Data Science   New.pdf\n",
      "[' Name: Shashikanth Kadam \\n\\n \\n\\nH:no : 12-7-156/2, New Mettuguda,  \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nEmail address: shashikanth_kadam@yahoo.co.in \\n\\nPhone#: 96520 – 96524.  \\n\\nSecunderabad – 500017. \\n\\n \\n\\nProfessional Overview:-- \\n\\n \\n\\nHave over 9 + years of overall work experience, out of which 8 months purely in Data/Pattern Analysis, Prediction model building, \\nMachine  Learning,  Business  process  improvements,  Visualization  and  R,  Python  Programming.  Holding  a  Bachelor’s  Degree  in \\nComputer science and information technology.   \\n \\n\\nSummary: \\n\\n\\uf0d8  Data Analysis, provide insights and provide necessary recommendations. \\n\\n\\uf0d8  Building prediction models using Machine Learning algorithms such as Decision tree, Naïve Bayes, k-NN, SVM and Neural \\n\\nNetworks. \\n\\n\\uf0d8  Data mining techniques such as Principle Component Analysis (PCA), Association rules and recommendation Systems, cluster \\n\\nanalysis. \\n\\n\\uf0d8  Time series analysis and building models based on the scenario to forecast the business interests. \\n\\n\\uf0d8  Text mining and sentiment analysis. \\n\\n\\uf0d8  Worked on R& Python Language,Tableau data Visualization tool,XL miner, MINITAB. \\n\\nTechnical Skillset: \\n\\n\\uf0d8  Skill set Data Mining Techniques: Market Basket Analysis, Apriori, K-means, KNN, Naive-Bayes, Decision Tree, Random Forest. \\n\\n\\uf0d8  Prediction Techniques: Linear, Logistic and Multinomial Regression.  \\n\\n\\uf0d8  Programming languages: R Programming, Python.  \\n\\n\\uf0d8  Statistical Tools: XL-Miner, MINITAB, R Studio. \\n\\n \\nPROFESSIONAL EXPERIENCE \\n\\nJr. Data Scientist \\n\\nExcelR Solutions (Nov 2017 – till date) \\n\\nSuccessfully completed Data Science course and worked on live projects as internship.  \\n\\n\\uf0d8  Analyzing, Interpreting patterns in large sets of data. \\n\\n\\uf0d8  Data Analysis, provide insights and necessary recommendations. \\n\\n\\uf0d8  Building various prediction models such as Linear models, Logistic models and Poisson model, negative binomial model based \\n\\non the scenario. \\n\\n\\uf0d8  Statistical analysis of various projects through usage of appropriate statistical techniques such as linear regression, Logistic \\n\\nregression, time series, segmentation, clustering, ANOVA. \\n\\n\\uf0d8  Build and validate the prediction models at project and unit level based on the business objectives. \\n\\n\\uf0d8  Collecting and aggregating the projects data at unit level and comparing it with the business objectives there by identifying the \\n\\ngaps to achieve the objectives. \\n\\n\\uf0d8  Providing solutions to the business problems by applying analytics techniques such as Regression, time series, clustering and \\n\\nMachine Learning \\n\\n\\x0c']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Currently working on project “Student’s school dropout’s” \\n \\nPurpose: Educational Data Mining (EDM) aims to knowledge discovery by applying mining techniques to identify hidden \\nknowledge and patterns about student’s drop outs from primary schools. \\n \\nThe idea is to help improve the overall quality of primary education by taking appropriate action based on the prediction in \\nschool dropouts. Early prediction helps in devising appropriate solutions to help schools address student’s dropout.  \\n \\n\\nProject 1:Student’s school dropouts \\n\\nBusiness Objective:-- Analyze the data and identify the key factors influencing the dropout’s and building the model using \\ndifferent techniques. \\n\\nTools : R \\n\\nPhase 1 :-- Collected the data from different websites. \\n \\nPhase II: -- Data Cleansing on the data extracted on relevant fields. \\n \\n\\nStudent Drop out (0=No, 1= Yes). \\nTime taken for each student to travel from home to school. \\nIncome of a Parent(per month). \\n\\n\\uf0a7 \\n\\uf0a7 \\n\\uf0a7 \\n\\uf0a7  Academic Performance. \\n\\uf0a7  Number of Co-curricular activities. \\n\\uf0a7 \\n\\uf0a7 \\n\\uf0a7 \\n\\uf0a7 \\n\\uf0a7 \\n\\uf0a7 \\n\\uf0a7 \\n\\nSchool environment. \\nSchool fees. \\nParents interaction with children at home (during HOMEWORK). \\nSchool accessible from home (In their region or area). \\nInterest in Studying. \\nProvision of Water Supply. \\nEngaged in Household works. \\n\\n \\nPhase III :--Segregated the data into structured and unstructured data. \\n \\n\\nTechniques used:--Machine Learning Algorithm Used: \\n\\n\\uf0d8  Logistic Regression \\n\\uf0d8  Naïve Bayes \\n\\uf0d8  Random Forest \\n\\n \\nThe inputs have been delivered to the client and we are awaiting a response from them.  \\n\\nOrganization: C3i Support Services Pvt, Ltd. \\n\\nDuration:- (Oct 2008 - Oct 2017) \\n\\nSr. SME & Consulting India – Tier2 (INFORMATION TECHNOLOGIES&SERVICES)& TECHNICAL SUPPPORT PROFESSIONAL) \\n\\n \\n\\n \\n \\n\\n \\n\\n \\n\\n \\n\\n\\x0c']\n",
      "[\" \\uf0a8  Competent,  diligent  &  result  oriented  professional,  offering  experience  across  Service  Delivery  Operations, \\nTroubleshooting  Functions,  Technical  Solutions,  Client  Servicing,  Reporting,  Critical  Projects  handling,  Recruitment, \\nTraining & Development; Meeting various clients to discuss their business problem and provide corrective solutions. \\n \\n\\n\\uf0a8  Excellent time management skills with proven ability to work accurately and quickly prioritize, coordinate and consolidate \\n\\ntasks; resilient with a high level of personal integrity and energy experience. \\n \\n\\n\\uf0a8  Core Competencies \\n\\uf0a8  Service Delivery Operations \\uf077Technical Solutions \\uf077 Client Servicing \\uf077 Recruitment \\uf077 Training & Development \\uf077 Critical \\n\\nProjects Handling  \\n\\n\\uf0a8  Client meeting and Analyzing Business  \\n\\n \\nJOB Skills:-      \\nInterfaces between C3i  and J&J client.  \\n\\n\\uf077 \\n\\uf077  Project Planning  \\n\\uf077  Project Execution \\n\\uf077  Resource Management  \\n\\uf077 \\n\\nSchedule Assessments and Management \\n\\nKey Accomplishments \\n\\n \\n\\n\\uf0a8  Commended for receiving Employee of the Month award in 2011.  \\n\\n \\n\\n\\uf0a8  Recognized and awarded HP certified engineer for the Product & training in during 2012. \\n \\n\\uf0a8  Selected & successfully completed Laptop migration project from Windows XP to Win 7 during 2012-2013.  \\n \\n\\uf0a8  Highly appreciated for selecting as a Product Specialist  (Veeva CRM)on iPad& successfully completed the deployment of \\n\\napplication and its training in 2014. \\n\\n \\n\\uf0a8  Received many client appreciations for successful completion of major projects. \\n\\n \\n\\n\\uf0a8  Was also proposed by U.S Management for onsite support for which I had to travel to US 3 times.  \\n \\n\\n \\n \\n\\nACADEMIC & PROFESSIONAL CREDENTIALS  \\n\\n\\uf0d8  B Tech (C.S.I.T) from Sant Samarth Engg, College (JNTU), Hyderabad. [2002 – 2006]. \\n\\uf0d8 Intermediate (M.P.C) from Nrupatunga Jr. College, Hyderabad [2000 – 2002]. \\n\\uf0d8 SSC from Amaravathi Grammar High School, Secunderabad [1999-2000]. \\n\\nComputer Proficiency \\n\\nMS Office (Microsoft word, Excel, Power Point), (Win'95/ 98, Win'2000, Win NT, Windows XP and Windows 7). \\n\\nITIL Foundation Certified in IT Service Management (Aug 2015).  \\n\\nVeeva CRM Certified (May, 2016).  \\n\\nCompleted Certified course on Data Science with Tableau, PYTHON and R from ExcelRSolutions. \\n\\n \\n\\n \\n\\n \\n\\n\\x0c\"]\n",
      "[' Personal Details \\n\\n: Late. Shivaji Kadam \\n: Roopkala Kadam \\n: 9th Aug 1983. \\n: Married \\n: Indian \\n: K3703907 valid upto September 2022. \\n: B1/B2 valid upto Dec 2023.  \\n: Marathi, Hindi, English, Telugu.  \\n: H.No: 12-7-156/2, New Mettuguda, Secunderabad – 500017.  \\n\\nFather’s Name   \\nMother’s Name  \\nDOB and Age \\n \\n \\nMarital Status \\n \\nNationality \\n \\nPassport no. \\nU.S Visa Type \\n \\nLanguages Known \\nPermanent Address \\n \\n \\nI hereby declare that, to the best of my knowledge and belief, all the information provided by me in this application is factual and \\ncorrect  \\n \\n\\nShashikanth Kadam \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n\\x0c']\n"
     ]
    }
   ],
   "source": [
    "# calling above function and extracting text\n",
    "path = \"C:\\\\Users\\\\LENOVO\\\\Desktop\\\\res\\\\resumes\\\\\"\n",
    "for filename in os.listdir(path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            print(filename)\n",
    "            for page in extract_text_from_pdf(path):\n",
    "                text = []\n",
    "                text.append( ' ' + page)\n",
    "                print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ashis_3yr_Infosys.pdf\n",
      "5/27/2019  ASHIS  PANDA DATA ANALYST  ashisk.akp@gmail.com   +917358270790  ashiskumarpanda    https://medium.com/@GeneAshis    https://www.linkedin.com/in/ashis- panda-b211b592/  CaptainAshis  Summary  Data Scientist with 3+ years of Experience executing data-driven solution to increase e\u0000ciency and accuracy. Experienced in creating machine learning models using predictive data modelling techniques and analyzing the output of the algorithm to deliver insights and  implement action oriented solutions to complex business problems.  Skills  PYTHON  SQL  R  DATA SCIENCE  MACHINE LEARNING ALGORITHMS  TABLEAU  PYTORCH  KERAS  MATPLOTLIB  NUMPY  PANDAS  DEEP LEARNING  SCIKIT LEARN  https://resume.creddle.io  Education  Creddle | Resume  Bachelor Of Technology in Electrical and Electronics Engineering at Vellore Institute of Technology , India  2011 to 2015  Employment  Infosys Analyst  Projects  Bangalore Dec. 2015 to Current  Developed the Dynamic pricing module for one of the largest Logistics Company in USA Our Client is a Freight company who acts as a broker between Clients who wants their loads to be transported and Truckers. They would get a quotation  price by their Clients for the load to be transported and would negotiate that amount with truckers. This was basically done by the Carrier Representatives in our Client company by using their existing domain knowledge and their years of experience in negotiating. Our main aim was to develop a dynamic pricing model which understands that given the factors involved, it can exactly come up with a price that has to be paid to the truckers. Responsibilities undertaken as a part of this project :- i) Developed the conceptual and analytical framework of the proposal, as well as the codes for the algorithm used for analysis.  ii) Implemented various ML model for all the lanes and the data was sequenced temporally.  iii) Used Random Forest , XgBoost , Ridge and Lasso models and took an ensemble approach on top of these models, to come up with the best model. iv) Worked directly on the client presentation as well as presented it to the client for the pitch. v) Trained other team members on the tools and techniques used for developing the Ensemble model.  Recommendation System I developed a Recommendation system using Neural Network. 1. A recommendation system, in general consists of a User and an Item. 2. Each user and each Item were randomly initialized with a set of random numbers also known as Entity Embedding. These embeddings were passed as an input to a Neural Network and it gets updated as we train our Neural Network. 3. At the end of our training, it’s found that the User and Movie embedding which were random values initially, has been updated during the training phase and these values starts making sense. These updated set of numbers represents the genre of Movies and the Preference of Users. 4.  Using these updated Entity Embedding a Recommendation system was developed.  Activities  Towards Data Science and Hackernoon publication. · Writer I work with Towards Data Science and Hackernoon publication as a Technical Writer. These are the biggest Machine Learning publication with an outreach of more than 100k subscribers. A couple of my blogs have received good appreciation from eminent deep learning personalities like Jeremy Howard (Deep Learning Researcher , President of Kaggle) and David Robinson (Chief Data Scientist at Datacamp) .   2018 to Current  Yes Bank · Guest Blogger YesBank selected my blog to cover about their mega Datathon event held at Bangalore.    Analytics Society Meetup I am a part of Analytics Society Meetup at my workplace. My responsibilities involve brainstorming concepts of Deep Learning and making the participants understand my experience of solving a project using Deep Learning approach.   Guest Lecture at Praxis Business School, Bangalore ·  I was invited for a session on Deep Learning at Praxis Business School, Bangalore .  1/1\n",
      "++++++++++++++++++++\n",
      "Ayan_cv_pdf.pdf\n",
      "AYAN MAZUMDER                      mazuayan@gmail.com   Contact No: 7829657213                                          Current Location: Mumbai (open                       to reallocation)              ----------------------------------------------------------------------------------------------------------------------------- ----------   FUNCTIONAL/TECHNICAL KNOWLEDGE:   •  Skill Sets (Tools): SQL, R, Power BI, Qlikview, MS Excel, MS power point, SAS (base)      •  Analytics Modules: Predictive modelling, logistic regression, linear regression,   segmentation, K means clustering, CLTV, campaign analytics, decision trees, CHAID, factor   analysis, market mix modelling, time series, forecasting, credit-risk, Data Science, retail   analytics, BFSI      WORK EXPERIENCE   Summary: Have over 36 months of analytics experience, implementing end to end analytics driven   business solutions for major Automotive, Retail, DTH and BFSI clients.   Tenure:   -  Senior Business Analyst (Analytics) in Hansa Cequity Pvt. Ltd. (April 2019- till date)    -  Business Analyst (Analytics) in Hansa Cequity Pvt. Ltd.  (Nov 2016-March 2019)   -  Analytics Analyst in ACCENTURE AI (CAMPUS HIRE) (Aug 2015- March 2016)      PROFESSIONAL PROJECTS @ Hansa Cequity:      Segmentation  of  Customer  Base  for  enriching  customer  experience  and  targeted   marketing for a leading automotive industry   •  Performed an end to end value based customer segmentation to differentiate a high valued   customer  from  a  middle  or  lower  valued  customer,  based  on  historical  transactions.   Methodology included extensive data preparation/manipulation in SQL and implementing   an unsupervised clustering algorithm in R to derive the final segments.   •  Use Cases: Implemented these segments across all business touchpoints for differential   customer  treatment  and  increasing  sales  through  precise  communications  and  targeted   marketing\n",
      "++++++++++++++++++++\n",
      "Calculating CLTV for a leading automotive industry   •  Built  a  mathematical  algorithm  plugging  in  statistical  models  to  calculate  the  lifetime   value(past+future) of a customer to understand his business value.   •  Use Cases: Implemented CLTV scores across all business touchpoints to make impactful   business communications with the customers thereby increasing retention and sales.                Repurchase and Referral models for a leading automotive industry:      •  Built  and  implemented  a  repurchase  model  (Logistic  regression  model)  to  track  down   customers with a high propensity to repurchase/next purchase.   •  Built and implemented a referral model (Logistic regression model) to identify customers   with a high propensity to refer.   •  Benefits:  Significant  increase  in  loyalty/referral  sales  and  campaign  cost  optimization   through precise marketing                  Lapsation and Revival Models for a leading Life Insurance client:      •  Built and implemented separate logistic regression models to identify customers who are   most likely to lapse their policies and customers who are most likely to revive their   policies   •  Benefits: Helps client to proactively design strategy to enhance value and retain   customers. Sending campaigns to the right audience helps in cost optimization                  Churn Model for automotive, retail and DTH clients:    •  Built an end to end churn model (Logistic regression model) to track down customers with   a high propensity to churn   •  Use Cases and Benefits: Sending customized campaigns to highly probable to churn   customers to increase customer retention      Projects @ Accenture:                  Market Mix Modeling for A LEADING TELECOM COMPANY   •  Scored Market Mix Models to find out the most efficient marketing source as in TV, Radio,   Newspaper, Campaigns for optimizing advertising budget.\n",
      "++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Mix Model for a leading TOY MANUFACTURING COMPANY(retail):   •  Measured the promotional uplifts as in the difference between baseline and actual sales  to find out the most effective promotional campaigns that were generating a higher lift in  sales                                                                        EDUCATION:     •  Masters in Economics from Jadavpur University, Kolkata (2015) - GPA  7.9     •  Bachelors in Economics from Jadavpur University, Kolkata (2013) - GPA  6.33    •  HSC/12th Higher Secondary from South Point High School, Kolkata (2009) – 71.8%     •  SSC/10th Madhyamik from South Point High School, Kolkata (2007) – 84.5%                                                                  NOTEWORTHY MILESTONES   •  Consistently rated among the top performers over the last two Financial Years   •  Won 6 quarterly awards at Hansa Cequity for excellence in performance   •  Have  won  several  awards  for  acing  Table  Tennis  and  Swimming  competitions  in  both   college and school\n",
      "++++++++++++++++++++\n",
      "Copy of Pooja Resume Data_-2019.pdf\n",
      "Pooja Vishwakarma      Contact No: ​91-7899632781;​ Email: ​Pooja03july@gmail.com ​Linekdln;​Pooja vishwakarma   Manyata Tech Park.  560045      Data Science & Automation Professional   Offering 3.6 years of experience across Machine learning, Artificial Intelligence; Automation; Rest Services;R; Python;   Seeking challenging assignments across Machine Learning, Artificial Intelligence & Data Analysis.                  PROFILE          ✓ Equipped with the knowledge of various Analytical skills and machine learning & artificial    intelligence   techniques , sound understanding & skill of creating new software & systems, designing, analysis, testing,     database development & coding for modules as per the requirements.   ✓ Possess knowledge of programming languages like C, C++, R, SQL, Python.   ✓ Good communication skills, verbal as well as written coupled with exceptional presentation skills with the                                                                                                     ✓ Focused individual with an analytic bent of mind and technical understanding coupled with creativity,      communication, debugging and problem-solving skills and confident to take challenging assignments.                                   ability to perform above expectations.                          TECHNICAL ​SKILLS    Programming Languages: ​C, C++, R, SQL and Python.  Theoretical Concepts: ​Data Structures, Analysis and design of algorithm, Object Oriented programming  language,Random Forest, Natural Language Processing, Artificial Neural Networks, Data base management,  Operating systems, Pattern recognition.  Tools used: ​R Studio, SQL server, MS Excel, MS Office, Anaconda,   Technical Training: ​Data Analysis using MS Excel and R and build the models using R & Python Languages.    Current organization    Organization: ​IBM india Pvt. Ltd.   Division: ​IT  Designation: ​Data scientist  Duration: ​feb 2016 till date    Project1: ​Enkana,sysco,Honda,Amul.  Description: ​Developed data Analysis skills based on using decision tree.    Programming Language Used: ​Python, Rstudio,Cognos       PAST EXPERIENCE   Organization​:​Loanshoppe  Division​:​Security Analyst    Designation​:​Security and Risk management  Duration​:​july 2014 to july 2015\n",
      "++++++++++++++++++++\n",
      "Key Deliverables  ✓ Analyzing the patterns in the data,data validation health check.   Projects Handled   Project1: ​GSNI    Description:  Da​ta validation,Data Healthcheck,Missing Values    Programming Language Used: ​UAT Tool,URT tool,Ms excel.           Technical Area of Expertise   ✓ Building the solutions by having the thorough knowledge on business domain of the clients .  ✓ Doing Literature survey to build Solutions to innovative ideas.  ✓ Holding experience of Solutions, calculated fields, Notifications Reports, Advanced Work Flow, Data feed,   Access Control, Questionnaires, Sub forms, Data Import, Creating multiple layouts, Packaging, Analyzing data,   Data analysis and observe the patterns.    ✓ Thorough Knowledge on Advance  MS Excel, R Language, Python, Rest Services, Data Analysis and Linux                                                                        Key Deliverables   ✓ Analyzing the patterns of problems in the Data  ✓ Literature survey to Choose better technique to solve Problem.  ✓ Designing and developing the system Using R Language.  ✓ Involve in requirement analysis, database design, coding, testing, implementation and maintenance of several                                        software applications.      Projects Handled   ● Description:  ●  Project1: ​Credit Risk Modelling.(4 mos)  Description: ​Worked on a project related to Financial Markets wherein I had to examine the trust worthiness of a prospective customer and  his/her possibility of defaulting on loan    Programming Language Used: ​R language ,Python.         ​The task was to build a Behavioural Credit Risk Model based on a large sample of data by applying     Logistic Regression.  ● The data had various information related to behaviour transactional details of the customers and their                                                                                              performance in repayment.   ● There were number of validation checks which were performed to test the robustness of the model                                                 under taken in terms of various goodness–of–fit statistics.    ● There were number of goodness of fit statistics which we had considered like Percent Concordant,      Hosmer – Lemeshow test, Wald – chi square and score tests.                                                Project2:  ​ENKANA (8 mos)    Description: ​Worked on​ ​a project related to Server based Incident data,labeling,analysis\n",
      "++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programming Language Used: ​R language, Sql, Machine learning     ●  ●  ●  ●  ●        The task was to build cognos visualization based on our data analysis using graph.   The data had various information related to Pending activity, SLA due,Error in backside Information and  prediction on various variable dataset   There were number of validation checks which were performed to test the robustness of the model under  taken in terms of various goodness–of–fit statistics.     Worked on data consolidation, pre-processing, entity extraction, ticket classification, Dynamic dashboard  creation and presentation with clients/TSM’s (Technical Solution Managers). Naïve Bayes classifier, KNN  classifier, SVM classifier, Decision tree classifier and SVD with cosine similarity are some of the classification  algorithms I worked on to classify IT tickets automatically.    Outlier/Anomaly detection: Working on different outlier techniques like Inter quartile range, Normalized  Z-score,  PCA for outlier detection. Deploy our Project with watson and get feedback based on accuracy,       Project3:  ​House selling data Price Prediction.(4 mos)  Programming Language Used: ​Python     ● Description:  ●  ​I have worked on House selling data Prediction via using different techniques,variable,Numerical and   categorical,data which is giving me final output using python​.   ● Natural  Language Processing (Text Minning)  ● Working on Advanced text analytics which includes Pre-processing, clustering, cluster labellingand KB   (knowledge base) document/information retrieval using different machine learningalgorithms.    ● Data Pre-processing involves, standard & account specific stop word removal, Entity extraction (using   regex or using predefined list–simple matching). K-means clustering, Connected components with  Graph & Affinity propagation are some of the clustering techniques I worked on to get clusters/groups  of similar issue tickets. Text Rank - A high frequency unigram based labeling & Two-level label  generation for document clusters using top keyword combinations.           ✓ R installations and programming.  ✓ Reading the research papers and applying those techniques to our problems  ✓ Understanding the patterns in the raw data using R Language and MS Excel and building the potential                                                   Technical Area of Expertise   Solutions for Problem.   ✓ Thorough Knowledge on MS Excel, Random forest, Data analysis and Machine learning concepts.       ACADEMIC CREDENTIALS        Bachelors in Engineering; ​Trinity institute  of Technology and Reserach, Rajiv Gandhi Technical  university ​Secured:​ 7. 0Percentile  Specialization:  ​Electronics and communication\n",
      "++++++++++++++++++++\n",
      "✓ Winner of Accenture hackathon 2017 globally.  ✓ Performed best analytics Rating in Project globally.  ✓ Got ​Prospera Techie​ during the quarter Oct-Dec 2016 From ​IBM.​.              Date of Birth: ​3rdJuly, 1992;​ Gender​:Female​;​ Language Proficiency: ​English, German, Hindi;   PERSONAL DETAILS\n",
      "++++++++++++++++++++\n",
      "DilipBehera_Resume.pdf\n",
      "Dilip Kumar Behera   +91-8895471553 | E: dilipbehera003@gmail.com      Mahadevapura, Bangalore, Karnataka 560037   PROFESSIONAL   SUMMARY   SKILLS   Business outcome oriented data scientist with 3.5 years of experience and a   proven ability of delivering powerful business insights via data science   methodologies   •  Python:   •  Tableau:Tableau   Numpy,Pandas,Matplotlib,Seaborn  Desktop,Tableau Prep   ,Scikit-learn,NLTK   •  Statistics   •  Machine Learning Algorithms   •  Advance Excel   Classification, Regression,   Clustering, CART, Dimension   Reduction Techniques, NLP and   Ensemble Methods   •  SQL                     WORK HISTORY   DATA SCIENTIST     10/2015 to CURRENT    Ericsson India Global Services | Bengaluru, KA   1.Project Summary :Sleeping Cell Predictions   •  Build a classification model on given historical data to analyze the traffic on   individual node and predicted the sleeping nodes.   •  Approach: Performed data preprocessing ,exploratory data analysis after   gathering data from multiple BU .Applied Logistic regression,LDA, KNN   ,SVM and Random Forest Algorithms.   2.Project Summary : Field Dispatch Prediction   •  Built a classification model for the tickets with issue and predict whether   the ticket needs to be dispatched or not   •  Approach:Performed data cleaning, Feature engineering and developed a   classifier using Bayes Theorem and NLTK package , also improved the   performance using ensemble method.   3.Project Summary: KPI Analysis And Optimization   •  Developed a model for predicting the network key performance Indicators   (Accessibility, Retainability, Mobility, RSSI) for Sprint   •  Approach:Performed exploratory data alalysis and then spot checked   various regression algorithms such as linear regression ,Ridge regression   ,KNN ,Elastic net regression and SVM   4.Project Summary: Dashboards and Reporting   •  Reported insights gathered from models through Tableau across internal   and external stakeholders.   •  Created a customized dashboard for quick KPI check after parameters   changes which saved 2520 minutes yearly.\n",
      "++++++++++++++++++++\n",
      "EDUCATION   ACCOMPLISHMENTS   HOBBIES                           •  Ensured timely submission of Daily/Weekly/Monthly/Quarterly/Annual   reports to respective stakeholders.   B.Tech | Electronics And Telecommunications    2015    Kalinga Institute of Industrial Technology, Bhubaneswar, OD   •  Graduated with 8.02 CGPA   •  Awarded Student Leader Medal for leading our college NCC group in the   republic day parade.   •  Named Appreciation from the Customer in Project Success Stories   Publication   •  Power Award for Q1, 2019    •  Ace Award for Q2 2018    Bodybuilding and Motorcycling\n",
      "++++++++++++++++++++\n",
      "Kuntal RoyChowdhury_Resume.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KUNTAL              ROY CHOWDHURY             Data Scientist   PROFILE      Microsoft   industry.  Skilled   Experienced  Senior  Associate  with  knowledge  of  time  series  analysis  in  automotive  in  R  programming,  Excel,  Microsoft  Word,  Data  Analysis,  Statistical  modelling  &  Data  Science.  Strong  professional  with  a  master’s  degree  statistics  and  computing  from  Banaras  Hindu  University.   focused   in   CONTACT   +91-9831464541   kroychowdhury121@gmail.com   Kolkata, India   https://www.linkedin.com/in/kunt al-roy-chowdhury-76a5b3135/   CERTIFICATION   Statistics with R Specialization   (MOOC by Duke university on Coursera)   EXPERIENCE   SENIOR ASSOCIATE | GENPACT    Jun,2018 - Present   ❖  I am working for a steel production management client- in  the  automotive  sector,  doing  demand  forecasting  for  the  upcoming year. The main aim being reducing the inventory  cost  of  the  company.  This  particular  project,  required  forecasting for diverse data which sometimes fluctuated with  no normal trend. Hence it had to be treated in different ways.  I  have  successfully  created  several  models  in  R  software,  namely  Ratio  to  Moving  Average,  Fourier  Transformation,  Croston,  Holt-winters  &  Double  Exponential  Each  model  is  used  to  deal  with  separate  types  of  data  altogether.  Automating them in R has raised the quality of the outcome  of the forecast, reduced the time taken and  can be  further  used by the company evenly.        ❖  I have also been generating a significant number of reports   on a daily basis by automating this process in R. This has  reduced manual error to a great extent and levelled up the  report results. Moreover, it has helped save time and effort  simultaneously.     ❖  Furthermore, I have actively tried to integrate tableau and   R, which has reduced the respective drawbacks of both the  tools.   Freelance statistics consultant (Internship)   Tutor Help Desk | Feb,2018 – June,2018   I provide consultancy for educational projects requiring  statistical analysis using R and SAS for the overseas  students.      EDUCATION   2018   2016   M.Sc. Statistics & Computing   Banaras Hindu University | CGPA: 7.41/10   B.Sc. (Hons) Statistics   University of Calcutta| Percentage: 57.125%   SKILLS   R Programming Language and Environment (Proficient)   Tableau (Intermediate)   License: WEZLK96UWP5R   Advanced Excel\n",
      "++++++++++++++++++++\n",
      "Megha_Resume.pdf\n",
      "Megha Kumari  Graduate Analyst Motivated , team-work oriented , and responsible Data Analyst with signiﬁcant experience in translating numbers into meaningful facts for businesses to help them make better business decisions. Aiming to utilize my skills and experience in predictive modelling , data processing , data mining , machine learning algorithms and strong analytical ability to solve challenging business problems.  meghak39@gmail.com  8145736126  Pune, India  linkedin.com/in/megha-kumari-542726a1  WORK EXPERIENCE Graduate Analyst Barclays 07/2018 – Present Achievements  SKILLS  R programming  Python  MySQL  Pune, Maharashtra  SAS  Tableau  Groovy  Built an analytics engine that makes use of activity logs across various digital channels of Barclays and predict possible customer journeys across these channels. Further identiﬁed the customer journeys which failed or were abandoned and the possible reasons associated with it to convert the data acquired into actionable insights. Built a sentiment analysis tool using Natural language Processing which identiﬁed positive as well as negative features of different digital channels by making use of NPS (Net Promoter Score) and reviews given by customers. JIRA AUTOMATION : Wrote groovy scripts to automate the task of creating an issue in Jira whenever any component of Barclays environment went down .  Data science Intern adglobal360 05/2017 – 07/2017 Achievements  Gurugram, Haryana  Maruti True Value Pricing engine : Built a prediction engine using ML techniques that predicts a tentative purchasing price by evaluating different parameters of the pre- owned cars. Used historical data to Train, Test and Reﬁne the model. Carried out various steps such as : Data pre-processing , Model designing and building , Model Analysis and Reﬁnement, Model Testing and Model Validation with various techniques and algorithms using R programming.  PERSONAL PROJECTS Safety Analytics, IIT Kharagur (01/2017 – 04/2017)  Research and data collection of different causes of accidents and types of accidents. Used various algorithms such as MLR , SVM , KNN , CART to analyse their performance on safety data based on different kinds of accidents and their causes. Analysed and studied different safety measures to be taken at a plant.  EDUCATION Bachelor of Technology Indian Institute of Technology, Kharagpur 07/2014 – 04/2018  Senior Secondary Chinmaya Vidyalaya 2012 – 2014  Secondary Chinmaya Vidyalaya 2012 – 2011  7.08 CGPA  86%  10 CGPA  Machine Learning  Data mining  Data Processing  Teamwork  Team Leadership  C  C++  NoSQL  HTML  CSS  POSITION OF RESPONSIBILITY Core Team Member , Composit IIT Kharagpur (2015 – 2017) • Publicized the fest in various colleges of Jharkhand and West Bengal and achieved a YoY increase of 200% in the participation • As a part of Corporate and Media Relations Team, was successful in bringing a total monetary amount of INR 2 lacs for the fest • Managed the accommodation of over 350 participants and served as a contact point for information dissemination • Conducted TECHNOVA, the ﬂagship event of COMPOSIT'16  Campus Aﬃliate , Kshitij IIT Kharagpur (2014 – 2015) • Worked with a team for 20 people for the publicity and ground level execution of events in Kshitij 2015. • Responsible for the in-house publicity of the online events of Kshitij 2015 among the 10,000 residents at the institute. • Publicized in colleges of West Bengal and Jharkhand getting the highest ever participation from the respective regions • Led the media campaign in Ranchi & responsible for 3 media articles in leading newspapers of the region. • Involved in Guest reception team during the fest  Secretary Dramatics (2015 – 2016) I was responsible for helping General Secretary ,Social and Cultural in organizing Dramatics events in hall when needed and coordinated with hall boarders for active participation in all Dramatics events at the inter hall level as well as open IIT level.  VOLUNTEER EXPERIENCE Students' Alumni Cell, IIT kharagpur (2014 – 2015) participated in the event PHONATHON wherein i personally contacted several alumni for institutes fundraising campaign  NSO Health and Fitness IIT kharagpur participated in Campus CLEANLINESS DRIVE organised by NSO Health and Fitness.\n",
      "++++++++++++++++++++\n",
      "Shashikanth Kadam - Data Science   New.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Shashikanth Kadam      H:no : 12-7-156/2, New Mettuguda,                      Email address: shashikanth_kadam@yahoo.co.in   Phone#: 96520 – 96524.    Secunderabad – 500017.      Professional Overview:--      Have over 9 + years of overall work experience, out of which 8 months purely in Data/Pattern Analysis, Prediction model building,  Machine  Learning,  Business  process  improvements,  Visualization  and  R,  Python  Programming.  Holding  a  Bachelor’s  Degree  in  Computer science and information technology.       Summary:     Data Analysis, provide insights and provide necessary recommendations.     Building prediction models using Machine Learning algorithms such as Decision tree, Naïve Bayes, k-NN, SVM and Neural   Networks.     Data mining techniques such as Principle Component Analysis (PCA), Association rules and recommendation Systems, cluster   analysis.     Time series analysis and building models based on the scenario to forecast the business interests.     Text mining and sentiment analysis.     Worked on R& Python Language,Tableau data Visualization tool,XL miner, MINITAB.   Technical Skillset:     Skill set Data Mining Techniques: Market Basket Analysis, Apriori, K-means, KNN, Naive-Bayes, Decision Tree, Random Forest.     Prediction Techniques: Linear, Logistic and Multinomial Regression.      Programming languages: R Programming, Python.      Statistical Tools: XL-Miner, MINITAB, R Studio.     PROFESSIONAL EXPERIENCE   Jr. Data Scientist   ExcelR Solutions (Nov 2017 – till date)   Successfully completed Data Science course and worked on live projects as internship.      Analyzing, Interpreting patterns in large sets of data.     Data Analysis, provide insights and necessary recommendations.     Building various prediction models such as Linear models, Logistic models and Poisson model, negative binomial model based   on the scenario.     Statistical analysis of various projects through usage of appropriate statistical techniques such as linear regression, Logistic   regression, time series, segmentation, clustering, ANOVA.     Build and validate the prediction models at project and unit level based on the business objectives.     Collecting and aggregating the projects data at unit level and comparing it with the business objectives there by identifying the   gaps to achieve the objectives.     Providing solutions to the business problems by applying analytics techniques such as Regression, time series, clustering and   Machine Learning\n",
      "++++++++++++++++++++\n",
      "Currently working on project “Student’s school dropout’s”    Purpose: Educational Data Mining (EDM) aims to knowledge discovery by applying mining techniques to identify hidden  knowledge and patterns about student’s drop outs from primary schools.    The idea is to help improve the overall quality of primary education by taking appropriate action based on the prediction in  school dropouts. Early prediction helps in devising appropriate solutions to help schools address student’s dropout.      Project 1:Student’s school dropouts   Business Objective:-- Analyze the data and identify the key factors influencing the dropout’s and building the model using  different techniques.   Tools : R   Phase 1 :-- Collected the data from different websites.    Phase II: -- Data Cleansing on the data extracted on relevant fields.     Student Drop out (0=No, 1= Yes).  Time taken for each student to travel from home to school.  Income of a Parent(per month).           Academic Performance.    Number of Co-curricular activities.                 School environment.  School fees.  Parents interaction with children at home (during HOMEWORK).  School accessible from home (In their region or area).  Interest in Studying.  Provision of Water Supply.  Engaged in Household works.     Phase III :--Segregated the data into structured and unstructured data.     Techniques used:--Machine Learning Algorithm Used:     Logistic Regression    Naïve Bayes    Random Forest     The inputs have been delivered to the client and we are awaiting a response from them.    Organization: C3i Support Services Pvt, Ltd.   Duration:- (Oct 2008 - Oct 2017)   Sr. SME & Consulting India – Tier2 (INFORMATION TECHNOLOGIES&SERVICES)& TECHNICAL SUPPPORT PROFESSIONAL)\n",
      "++++++++++++++++++++\n",
      "  Competent,  diligent  &  result  oriented  professional,  offering  experience  across  Service  Delivery  Operations,  Troubleshooting  Functions,  Technical  Solutions,  Client  Servicing,  Reporting,  Critical  Projects  handling,  Recruitment,  Training & Development; Meeting various clients to discuss their business problem and provide corrective solutions.       Excellent time management skills with proven ability to work accurately and quickly prioritize, coordinate and consolidate   tasks; resilient with a high level of personal integrity and energy experience.       Core Competencies    Service Delivery Operations Technical Solutions  Client Servicing  Recruitment  Training & Development  Critical   Projects Handling      Client meeting and Analyzing Business      JOB Skills:-       Interfaces between C3i  and J&J client.        Project Planning     Project Execution    Resource Management      Schedule Assessments and Management   Key Accomplishments        Commended for receiving Employee of the Month award in 2011.         Recognized and awarded HP certified engineer for the Product & training in during 2012.      Selected & successfully completed Laptop migration project from Windows XP to Win 7 during 2012-2013.       Highly appreciated for selecting as a Product Specialist  (Veeva CRM)on iPad& successfully completed the deployment of   application and its training in 2014.       Received many client appreciations for successful completion of major projects.        Was also proposed by U.S Management for onsite support for which I had to travel to US 3 times.           ACADEMIC & PROFESSIONAL CREDENTIALS      B Tech (C.S.I.T) from Sant Samarth Engg, College (JNTU), Hyderabad. [2002 – 2006].   Intermediate (M.P.C) from Nrupatunga Jr. College, Hyderabad [2000 – 2002].   SSC from Amaravathi Grammar High School, Secunderabad [1999-2000].   Computer Proficiency   MS Office (Microsoft word, Excel, Power Point), (Win'95/ 98, Win'2000, Win NT, Windows XP and Windows 7).   ITIL Foundation Certified in IT Service Management (Aug 2015).    Veeva CRM Certified (May, 2016).    Completed Certified course on Data Science with Tableau, PYTHON and R from ExcelRSolutions.\n",
      "++++++++++++++++++++\n",
      "Personal Details   : Late. Shivaji Kadam  : Roopkala Kadam  : 9th Aug 1983.  : Married  : Indian  : K3703907 valid upto September 2022.  : B1/B2 valid upto Dec 2023.   : Marathi, Hindi, English, Telugu.   : H.No: 12-7-156/2, New Mettuguda, Secunderabad – 500017.    Father’s Name    Mother’s Name   DOB and Age      Marital Status    Nationality    Passport no.  U.S Visa Type    Languages Known  Permanent Address      I hereby declare that, to the best of my knowledge and belief, all the information provided by me in this application is factual and  correct      Shashikanth Kadam\n",
      "++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "  for filename in os.listdir(path):\n",
    "        if filename.endswith(('.pdf')):\n",
    "            print(filename)\n",
    "            for page in extract_text_from_pdf(path):\n",
    "                page = page.replace('\\n', ' ')\n",
    "                page = page.strip()\n",
    "                print(page)\n",
    "                print(\"++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt\n",
    "import os\n",
    "def extract_text_from_doc(path):\n",
    "    temp = docx2txt.process(path+filename)\n",
    "    text = [line.replace('\\t', ' ') for line in temp.split('\\n') if line]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1544684526313_Resume_Akshay_P.docx\n",
      "Arpit Bhatt\n",
      "Assistant Mechanical Engineer \n",
      "   \n",
      "M: 09468517613     E: arpit9nov@gmail.com\n",
      "PERSONAL SUMMARY\n",
      "An energetic and dedicated candidate with more than 3.8 years of experience in in Business Intelligence & Analytics domain focusing on Data Science ,ETL process & visualization using Python, Tableau and Informatica power center as Primary Tools/Language seeking a suitable position in an organization having a proactive and learning culture.\n",
      " ACADEMIC QUALIFICATIONS:\n",
      "ACADEMICS\n",
      "QUALIFICATION\n",
      "UNIVERSITY/COLLEGE\n",
      "YEAR OF PASSING\n",
      "Percentage\n",
      "GRADUATION\n",
      "B.TECH        Mechanical Engineer\n",
      "Maharishi Arvind Institute of Technology, Jaipur, Rajasthan\n",
      "2014\n",
      "68.54\n",
      "TECHNICAL COMPETENCIES:\n",
      "Operating Systems\n",
      "Windows, Mac\n",
      "Programming languages\n",
      "Python, R for Data Analytics\n",
      "Tools/Utilities\n",
      "Py-charm, R-Studio, Tableau, Excel.\n",
      "WORK EXPERIENCE\n",
      "Organization: Ganga Fashions Pvt. Ltd. (3.5 years)\n",
      "Responsibilities:\n",
      "Having 3.5 years of experience in Analytics domain with expertise in providing business solutions in Functional as well as Technical approach.\n",
      "Structuring the data where ever required using python package pandas.\n",
      "Analyzing the feed using various packages such as seaborn and matplotlib.\n",
      "Performing Exploratory data analysis on Datasets.\n",
      "Experience with web crawling using selenium and Beautiful soup.\n",
      "Knowledge of machine learning models in sklearn. Worked with logistic regression.\n",
      "Automated Quarterly validations process using python.\n",
      "Extensive experience in automation, data, visualization technology.\n",
      "Experience in designing complex Operational, Strategic and Analytical Dashboards and taking advantage of all tableau functions including data blending, parameters, Hierarchies feature, sets, Forecasts etc.\n",
      "Created multiple KPI Dashboards for sales and financial analysis by providing detailed analysis on MTD/YTD/YTG actual v/s target sales\n",
      "Involved in Database testing and possess good knowledge on writing SQL queries.\n",
      "Experience in creating and working with complex SQL Queries.\n",
      "Managing Dashboards build on Tableau. Changing and maintaining logics in worksheets/dashboards and accommodating new requirements from users in existing reports.\n",
      "Well experienced in Creating Mappings/workflows using Informatica Power center.\n",
      "Involved in implementing and testing SCD type 1, SCD type 2, SCD type 3 requirements in Informatica.\n",
      "Automated Daily report creation on excel using VBA scripts.\n",
      " \n",
      "REPRESENTATIVE PROJECT EXPERIENCE:\n",
      "Project # –UAustin Animals Center \n",
      "Project Description\n",
      "Using  datasets of intake information including breed, color, sex, and age from the client, we had to predict the outcome for each animal. Also helped client to understand trends in animal outcomes. These insights helped shelters focus their energy on specific animals who need a little extra help finding a new home.\n",
      ".  \n",
      "Structuring the data where ever required using python package pandas.\n",
      "Analyzing the feed using various packages such as seaborn.\n",
      "Performing Exploratory data analysis on Datasets.\n",
      "Applying Multiclass Classification Algorithm for prediction using sklearn.\n",
      "Automated quarterly validation process Using Python.\n",
      "Project # –UK Logistics supply chain \n",
      "Project Description\n",
      "UK Based Food supply Chain Company had a requirement for analyzing which ship port would is safest for the company to be used for supplying its products across the globe. We had to take in the key factors (crime rate, illiteracy rate, average income and population size) to analyze safest port to carry out their operations.   \n",
      "Structuring the data where ever required using python package pandas.\n",
      "Analyzing the feed using various packages such as seaborn and matplotlib.\n",
      "Performing Exploratory data analysis on Datasets.\n",
      "Applying logistic regression using sklearn.\n",
      "Automated quarterly validation process Using Python.\n",
      "Project # - Schneider Reporting India\n",
      "Project Description\n",
      "Schneider Electric India had all its BI reporting operations on Microsoft excel and it was very tedious task to maintain all India reporting operations in excel and required lot of manual effort. ETL and reporting solution was provided to migrate the whole process on Tableau Reporting Tool. Worked at Client location and was involved end to end from Data modelling phase to Development of Informatica Mappings to implement Data model. \n",
      "Involved in implementing and testing SCD type 1, SCD type 2, SCD type 3 requirements in Informatica.\n",
      "Responsible for development of mappings for dimensions and facts, Data loading and code migration activities.\n",
      "Performed manual data testing using SQL Queries.  \n",
      "Managing Dashboards build on Tableau.\n",
      "Created multiple KPI Dashboards for sales and financial analysis by providing detailed analysis on MTD/YTD actual v/s target sales\n",
      "ACHIEVEMENTS & INITIATIVES: \n",
      "Received “INSTA” award for development of mappings and workflows in Schneider Electric.\n",
      "Completed Infosys certified “BI Informatica Professional -Basic” certification.\n",
      "Attended trainings for Tableau, Big Data.\n",
      "Actively participating in competitions held on kaggle for machine learning.\n",
      "PERSONAL PROFILE:\n",
      "Date of Birth:   20-12-1992\n",
      "Father’s Name:  Anil Kumar Purohit\n",
      "Languages Known: English, Hindi\n",
      "Gender: Male\n",
      "Marital Status:  Single\n",
      "4\n",
      "Abhijeet_Resume_DA (4).docx\n",
      "ABHIJEET GUPTA       +919591508918           abhi.jeet_gupta@yahoo.com\n",
      "Professional Overview:\n",
      "I have completed M.Tech from IIT Madras in Thermal Engineering with overall 4.5 Years of work experience in Mercedes Benz R & D India. An astute professional with 2 years of work experience in Data Analysis, Prediction model building, time series and 2.5 Years in Computational Fluid Dynamics (CFD)\n",
      "Summary\n",
      "  Data Analysis , provide insights and provide necessary recommendations\n",
      "  Building prediction models to predict the temperatures of specific components there by assessing the risk of not meeting the business goals\n",
      "  Data mining techniques such as Principle Component Analysis (PCA), Association Rules, Linear Regression, Logistic Regression and  Cluster Analysis \n",
      "  Machine learning algorithms such as Decision Tree, Random Forest, k-NN\n",
      "  Forecasting or time series concepts\n",
      "  Worked on R, Excel, Minitab, XL Miner and slightly on Python and SQL\n",
      "  Trained IIT-JEE students with Algebra and Statistics\n",
      "  CFD (3D) to estimates temperatures and mass flow rates of different components of vehicle\n",
      "  Performed VTM simulations using Co-simulations and CHT (Conjugate Heat Transfer)\n",
      "  Automated some of the repetitive CFD tasks Using JAVA\n",
      "Skill Set:\n",
      "Data Analysis  \n",
      "Exploratory Data analysis\n",
      "  Data mining /Machine Learning\n",
      "  Building prediction models\n",
      "  Clustering Analysis, PCA\n",
      "  Associations rules\n",
      "  Time Series using XL Miner\n",
      "  Text Mining\n",
      "  R, Python\n",
      "  Excel\n",
      "  Minitab\n",
      "Technical \n",
      "  Heat Transfer\n",
      "  Fluid Dynamics\n",
      "  C language\n",
      "  StarCCM+\n",
      "  FLUENT\n",
      "Diploma/Certifications and Positions of Responsibilities:\n",
      "3 Years of voluntary teaching experience as a IIT JEE Mathematics faculty\n",
      "Teaching Assistantship in IIT Madras for Numerical methods which involves expertise in C\n",
      "DATA ANALYTICS \n",
      "Project 1:  Data Analytics – Predict surrounding temperature of brake disc\n",
      "Tools: R and Excel\n",
      "Techniques: Linear Regression, scatter diagram, Normality check, added variable plot, VIF, Residual plots, Index plot, \n",
      "Objective: To predict surrounding temperature of brake disc\n",
      "Surrounding temperature of brake disc is dependent on temperature of brake disc and vehicle speed\n",
      "Using Multiple linear regression, surrounding prediction model was built which involves initial exploratory data analysis\n",
      "It also involved finding if input variable has any collinearity problem using scatter plot and correlation matrix\n",
      "After verifying, prediction model was built\n",
      "Coefficient of determination (R2) was found to be 86 %\n",
      "Now this model is been used to calculate surrounding temperature and hence for brake cool down analysis\n",
      "Using this prediction model there was a huge saving on computation which could have incurred on doing brake doing analysis using 3D CFD\n",
      "PROJECT 2:  Data Analytics using MACHINE LEARNING – If to accept brake disc or not\n",
      "Tools: R and Excel\n",
      "Techniques: Logistic Regression, Decision tree\n",
      "Objective: To identify those brake disc designs which are feasible\n",
      "We received a data set for brake disc with input variables of different areas, volumes, heat transfer coefficient, cool down time and output variable as discrete if to accept the brake design or not based on input data \n",
      "Logistic regression model is built for this problem\n",
      "Residual deviance was found to be lesser than Null deviance which has given the indication that input variable were contributing to output variable\n",
      "Accuracy was found to be 83% using cross-table\n",
      "Similar model was also built using Decision tree\n",
      "PROJECT 3: Data Analytics using MACHINE LEARNING – Clustering Heat Exchanger\n",
      "Tools: R\n",
      "Techniques: Hierarchical clustering and K-means clustering\n",
      "Objective: To cluster different heat exchangers based on its performance and data \n",
      "Input data were In-temperature, out-temperature, mass flow rate and heat rejection through different designs of heat exchanger\n",
      "Based on given data, Euclidean distance formula was used to identify similarities for Hierarchical clustering\n",
      "K-means clustering was also implemented and found K value using elbow curve \n",
      "3D CFD PROJECTS\n",
      "PROJECT 1: Method Development on Co-simulation\n",
      "Conjugate heat transfer takes significantly more computational time \n",
      "Co-simulations takes less computational time comparatively when compare to conjugate heat transfer\n",
      "Developed an in-house macro to map fields (reference temperature, heat transfer coefficient & wall temperature) between steady fluid and moving solid \n",
      "Validated the macro for co-simulation with conjugate heat transfer results\n",
      "PROJECT 2: Vehicle Thermal Management Simulations\n",
      "It is the combination of under-hood(flow) and solid simulation  \n",
      "Under-hood considers only convection as mode of heat transfer\n",
      "Solid simulation considers both conduction and radiation modes of heat transfer\n",
      "Both Conjugate heat transfer and Co-simulations are used\n",
      "PROJECT 3: Under-hood Simulations\n",
      "Temperature distribution in the under-hood region in Car\n",
      "Automobile Under-hood consists of 8000 parts for which data is analyzed in terms of temperature\n",
      "Rotating wheels are modelled using rotating wall BC, Moving reference frame used to model fans \n",
      "Heat exchangers are modelled using porous media with inbuilt single stream heat exchanger models in STAR-CCM+\n",
      "As, it is complex geometry, surface prepping is done with the help of surface repair tool in STAR-CCM+\n",
      "Educational Qualification:\n",
      " Program\n",
      " Institution\n",
      " % or CGPA\n",
      " Year of completion\n",
      " M.Tech in Thermal Engineering\n",
      " IIT Madras, Chennai\n",
      " 8.77\n",
      " 2013\n",
      " B.E in Mechanical Engineering\n",
      " Vasavi College of Engineering,\n",
      " Osmania University, Hyderabad \n",
      " 84\n",
      " 2011\n",
      " 12th\n",
      " Vidya Vikas Junior College, Hyderabad\n",
      " 95.6\n",
      " 2007\n",
      " 10th\n",
      " Shri Gujarati Vidya Mandir High School, Hyderabad\n",
      " 81.67\n",
      " 2005\n",
      "Personal Details:\n",
      "Name: Abhijeet Gupta\n",
      "E-mail: abhi.jeet_gupta@yahoo.com\n",
      "DOB: 29th Dec, 1989\n",
      "Contact: +91 9591508918\n",
      "Language Proficiency: English, Hindi, Telugu and beginner in German and Arabic\n",
      "Permanent Address: Flat no. 209, Shree Keerthy Elite Apts, Channasandra, Whitefield, Bangalore – 560067\n",
      "DECLARATION:\n",
      "I hereby declare that all the above furnished details are true to the best of my knowledge\n",
      "Date: 01/22/2017                                                                                 ABHIJEET GUPTA\n",
      "Place: Bangalore\n",
      "Resume (1).docx\n",
      "Akshay K\n",
      "akshaykumar.2702@gmail.com   \n",
      "7899620118\n",
      "Bangalore, India\n",
      "       \n",
      "_________________________________________________________     \n",
      "Education/Certifications\n",
      "Bachelor of Technology in Electronics, Gitam University, Sept 2014\n",
      "CBSE Board Exam for Senior secondary school from AFGJI,New Delhi. Apr 2009\n",
      "ICSE Board Exam for High School from St.Josephs Public School,Hyderabad. Apr2007\n",
      "_________________________________________________________     \n",
      "Work Experience\n",
      "Quantafic Business Solutions    Nov 2017  –  Present\n",
      "Business Analyst\n",
      "Skillset:Python,R,SAS,SQL,Tableau\n",
      "• Led a team of 10 decision scientists to design/implement a global customer retention program for the flagship product (Financial and Risk) of a $40B information and media firm; Targeted users leveraging regression models, improving customer touch points/user experience to improve customer retention\n",
      "• Led BI team of a marketing and analytics engagement to create effective visualizations on Tableau; Integrated critical insights from multiple business groups of financial information firm and enabled renewal of negotiations, product and business development\n",
      "• Aligned with regional and corporate sales heads to generate new leads across Europe; Created multiple proposals and landed pilot engagements\n",
      "• Machine Learning using Regression model to predict the likelihood of a customer defaulting. Fraud and Credit Risk Analysis based recommendation\n",
      "• Fraud and Credit Risk Analysis based recommendation to BFSI clients. Decision Tree and Random Forest to find the highest risk segment.\n",
      "Tiarion Software      Jun 2014  –  Nov 2017\n",
      "Data Scientist\n",
      "Skillset:Python,R,SAS,SQL,Tableau\n",
      "• Developed an interactive algorithm for the sales team of a leading search engine to select most effective word clusters using text mining in R to pitch to 5k+ Travel and Retail clients, increasing website traffic and revenue\n",
      "• Enabled a leading technology company, lagging behind market leader, to uncover revenue opportunity by identifying 1000+ advertisers through big data assisted demand and supply gap analysis\n",
      "• Collaborated with client’s product engineering team to analyze impact of search advertising product roll outs; Provided recommendations to optimize advertiser campaigns that led to increase in new product adoption\n",
      "• Advised the CEO of a luxury travel firm on strategies to penetrate younger customer segment, by transitioning marketing activities from traditional (offline) to digital channels\n",
      "• Devised strategic initiatives for the marketing team of a retail giant in the Middle East; Leveraged data analytics/structured problem solving to drive sales in 13 countries through customer loyalty program\n",
      "• Led a 5 member team to design a recommendation engine for a $160B Fortune 100 technology company; Increased sales through its commerce work space by creating cross-sell opportunities\n",
      "Rithesh_KV.docx\n",
      "Rithesh Kumar KV\n",
      "E-mail     §   ritheshkumar88@gmail.com\n",
      "LinkedIn §   https://www.linkedin.com/in/rithesh-kumar-kv-425ab21/\n",
      "Github     §  https://github.com/ritheshkv/Analytics\n",
      "Phone      §   9930651375\n",
      "Address   §   G-2, No 4121-H, Indiranagar, Bengaluru-560008\n",
      ",\n",
      "                             PROFESSIONAL SUMMARY\n",
      "Analytics enthusiast with an experience of more than 5 years with  2+ years of experience in R programming  and SQL with the ability to communicate findings to the management and implement them to achieve organization goals. \n",
      "Experience in predictive modeling using machine learning algorithms such as Regression and Data Visualization.\n",
      " \n",
      "Excellent analytical and problem solving skills with attention to details and team leading capabilities. Ability to handle multiple projects while producing high quality work in a fast paced and deadline oriented environment.\n",
      "                            TECHNICAL SKILLS\n",
      " Excel, SQL, R Programming, JIRA, Predictive Modeling\n",
      "                                                WORK EXPERIENCE\n",
      "Analytics Quotient Pvt Ltd                                                                                   September 2017 — Present\n",
      "Senior Business Analyst\n",
      "Built a report generator dashboard in SQL by aggregating various data sources.\n",
      "Built a gender prediction model with a prediction accuracy of around 75%.\n",
      "Designed and guided the team on data preparation of NPS dashboard for the client.\n",
      "Guided the team in setting up ETL process from various data sources.\n",
      "Guided the team on the process of migration of database from MySQL to Redshift.\n",
      "Hansa Cequity Pvt Ltd                                                                                   April 2016 — March 2017\n",
      "Business Analyst\n",
      "Implemented CLTV  for client in auto sector to score customers based on lifetime value generated\n",
      "Built repurchase model in R which had a lift of 1.75 which was used for marketing campaigns\n",
      "Built lead scoring model in R which had a lift of 1.5 which was used for scoring the leads\n",
      "Created dashboards for tracking sales at the dealership level for client in auto sector\n",
      "Intrepid Online Retail Pvt Ltd                                                                January 2013 — January 2014\n",
      "QA Engineer\n",
      "Single resource responsible for software testing of the website\n",
      "Data Mining using SQL queries\n",
      "Igate                                                                                                              August 2010 — November 2012\n",
      "Software Engineer\n",
      "Extracted data from banking clients using Microsoft SQL Server\n",
      "Testing of webapp of clients in Insurance domain\n",
      "Fetched data  through VAX database system\n",
      "                                                              PROJECTS\n",
      "CLTV: \n",
      "Analyzed the data for 2 Million customers of automotive company.\n",
      "Calculated the total revenue generated by customers till date\n",
      "Added future revenue with Repurchase model (predictive model) with certain assumptions to each customer.\n",
      "Combined the past and future revenue streams to arrive at a combined Customer Lifetime Value(CLTV) for each customer\n",
      "Lead Scoring Model:\n",
      "Scored  5 Lakh prospects who were  opening leads through Web and automotive Relationship Centre\n",
      "Used demographic variables to check the data health of all the leads captured in the database.\n",
      "Used Logistic Regression model to predict the probability of leads opening enquiries.\n",
      "Refreshed the model every 4 months to check for out of time validity.\n",
      "Gender Prediction Model:\n",
      "Built a classification model to predict the gender of subscribers for an entertainment industry client.\n",
      "Aim was to increase female subscriber base of the client compared to its competitors.\n",
      "Used Logistic Regression and Random Forest methods to achieve around 80% accuracy on the train as well as test data.\n",
      "  \n",
      "EDUCATION\n",
      "PGDM                                                                                                                           July 2014 — April 2016\n",
      "K.J. Somaiya Institute of Management, Mumbai, Maharashtra\n",
      "Summer Internship Project:  CetKing\n",
      "Worked on Digital Marketing Strategy delivery including content writing, SEO, social media campaign\n",
      "BE                                                                                                                     September 2006 — June 2010\n",
      "NMAMIT, Nitte, Karnataka\n",
      "                Final Year Graduation Project:  Secured Electronic Box\n",
      "Designed, manufactured and tested a prototype of a secured Electronic Box which  was \n",
      "Microcontroller based under the guidance of Prof Chandramohan, NMAMIT, Karnataka\n",
      "           \n",
      "ACHIEVEMENTS\n",
      "Won Bech Daal, an intra-college socio-marketing Competition.\n",
      "Secured AIR-107 in CMAT exam of September 2013.\n",
      "Secured AIR-279 in COMEDK exam of 2006.\n",
      "CERTIFICATIONS\n",
      " Completed the course “The Analytics Edge” from edX  \n",
      "  Certified in R and SQL from Jigsaw Academy\n",
      "INTERESTS\n",
      "            Trekking, Video-games, Puzzles and Mathematics\n",
      "Rithesh Kumar KV\n",
      "Rithesh Kumar KV\n",
      "1\n",
      "1\n",
      "Santhosh Kumar S P.docx\n",
      "Resume\n",
      "Santhosh Kumar S P                     Email: santu4it@gmail.com\n",
      "              Phone: +91-9900499644\n",
      "Profile\n",
      "A Professional Data Science analyst with rich experience of Team Leading and Advisory Consulting roles. Quick to grasp new ideas, concepts, to develop innovative and create solutions to problems. Able to work well on my own initiative and can demonstrate the high levels of motivation required to meet the deadlines.\n",
      "Objective\n",
      "I am looking for challenging opportunities in an organization, which should provide me an opportunity to learn and grow in environment that provides exposure to cutting edge in technology thereby contributing to the growth of an organization.\n",
      "Summary\n",
      "Hands on experience in Base R programming, R Studio, Minitab, Tableau and XL miner.\n",
      "Experience in entire data science life cycle, i.e., source =>clean=>explore=>communicate.\n",
      "Strong experience in converting unstructured data into structured and workable datasets.\n",
      "Expertise in data exploration techniques using various statistical tools.\n",
      "Strong background in Machine Learning and basic knowledge in Deep Learning, NLP, Neural networks and Artificial Intelligent.\n",
      "Good command on prediction modelling techniques like simple linear regression, multiple linear regression and logistic regression analysis techniques.\n",
      "Good exposure to data mining techniques like Clustering, Principle Component Analysis and Market basket analysis.\n",
      "  Knowledge on Machine learning algorithms such as Decision tree, Naïve Bayes, k-NN, SVM & Neural networks.\n",
      "Good experience in data visualization techniques using Tableau visualization for final report communication to client.\n",
      "Strong knowledge in PMP and good End-To-End project implementation and Roll-out experience.\n",
      "Rich industry experience in products launching and product life cycle.\n",
      "Good hold on data modeling techniques and client communication.\n",
      "Developing, managing & tracking Project Plans with reporting to senior management.\n",
      "Adapt and adhere to industry standards while working with multi-cultural teams.\n",
      "Strong experience in design and development of web applications and as well as rebranding and redesign.\n",
      "  Good experience of working on open source technologies like TEAMSITE, HYBRIS and NEMO.\n",
      "Strong experience of working on QA tools like Bugzilla, Jira and Trello.\n",
      "Experience of working as a PHP developer in client-based project as well in R&D department.\n",
      "Good knowledge in SEO and basic knowledge on Omniture techniques.\n",
      "Key technical Skills\n",
      " Software\n",
      "  R Programming language\n",
      "  R studio\n",
      "  Minitab\n",
      "  Tableau\n",
      "  XL miner\n",
      "  Basic knowledge on Python.\n",
      "Mathematical and statistical\n",
      "  Good statistical and as well as good mathematics background knowledge.\n",
      "Other knowledge areas\n",
      "Programming Languages: PHP, Basic Java.\n",
      "Scripting: Java Script.\n",
      "Web Technology: HTML, HTML5, CSS, CSS3, JQuery.\n",
      "Database: MySQL.\n",
      " Defect Management Tool(s): Bugzilla, Jira, Trello.\n",
      "Tools & Concepts: Data Structure, Design Patterns, XML.\n",
      "Content Management System: Teamsite, Hybris.\n",
      "      Employment Chronology\n",
      "Total work experience: 11.5 Years (9 Years in ecommerce + 2.5 Years Data Science).\n",
      "Company: Lenovo, Duration: July 2007 to Aug 2017.\n",
      "  Working in the professional capacity of Data Science analyst.\n",
      "  Analyze large datasets to provide strategic direction to the client for data driven decision making.\n",
      "  Perform various statistical/mathematical techniques to bring out meaningful insights.\n",
      "  Use statistical tools for cleansing, exploration, predictive modeling, and hypothesis determination.\n",
      "  Determining the business problem and guiding the team through resolution process.\n",
      "  Communicate findings of data analysis with the client and generating reports for stakeholders.\n",
      "  Provide technical help like programming code to team along with resource management.\n",
      "  Managing hardware and software requirements to team.\n",
      "  Worked as professional Announce Lead for all new products on web as well key player in rebranding, redesign and promotions of products.\n",
      "  Managing support for a brand new implementation from the scratch, heavy client interaction as per project.\n",
      "  Establishing and settling new processes and good trainer for new team members.\n",
      "  Accommodating new requirements from the clients including design changes/updates.\n",
      "  Worked on opinion lab reports and improved the overall site quality based on CSAT reports.\n",
      "  Implementing Strategy Design Pattern for product Execution.\n",
      "  Played a role of guiding the team for any bottleneck, design or development issues and in introducing new functionality in application.\n",
      "  Duties included integration of team, attending meetings, and the review of requirements, environment setup, task assignments, monitoring and reviews.\n",
      "  Part of Knowledge Management, Organized the monthly knowledge sharing sessions for different teams that covered a wide range of topics on domain, project management and soft skills as well.\n",
      "Company: Virgosys, Duration: August 2005 to July 2007.\n",
      " Involved in design and development of GUI screens.\n",
      " Involved in understanding the data flow and business requirements of the using MVC architecture for the development on UI using JAVASCRIPT, JQUERY, and CSS.\n",
      " Creating product contents & modifying existing contents involving all the business logic, Making Web Service    \n",
      "          call from the UI to get all the required information from fetching data from DB & provide required data to UI.\n",
      " Done with design and services documentation for upcoming projects.\n",
      " Worked on Requirement Analysis, Code Analysis of existing system, and Development for application enhancements, Testing and Code Validation.\n",
      "Project work Snapshot\n",
      "Project 1:  TEXT ANALYTICS USING MACHINE LEARNING\n",
      "Tools: R\n",
      "Techniques: Naïve Bayes Machine Learning algorithm\n",
      "Objective: To classify the text records which are logged by customers in opinion lab, in to different classes and route them to respective teams to act on requests.\n",
      "Customers log their requests related to enquiries, Issues they face and any clarification they needed. Also third party log the requests related to claims clarifications etc. Currently classification is being done manually by domain experts. Considered the data in opinion lab division, defined and standardized the classes definitions. Got training data set coded manually with the standardized definitions.  Divided the data set in to training and validation sets respectively. Data pre- processing techniques included– removing stop words, extra white spaces, numbers, stemming the words. Tokenization was done using Document Term Matrix and sparse matrix was built. Built the Naïve Bayes model and validated the model using validation set. Accuracy of the model was improved by changing the Laplace constant. Finally model accuracy was at 83%.\n",
      "PROJECT 2:  ACCEPTING NEW LAPTOP OFFER\n",
      "Tools: R \n",
      "Techniques: Decision tree\n",
      "Objective: To identify those customers who will likely accept the offer of new personal laptop.\n",
      "The customer base of Asset customers was quite small, and the company wanted to grow this base rapidly to bring in more laptop business. Specifically, it wanted to explore ways of converting customers to provoke to by new laptop.  Considered the data provided by the other team containing personal details of the individual customers. Performed the EDA on the data set provided and built decision tree model based on the previous behaviour of the customers to analyze that what combination of parameters make a customer more likely to accept a laptop.\n",
      "PROJECT 3: BUILDING PREDICTION MODEL FOR VEHICLES OF A FIRM\n",
      "Tools: R\n",
      "Techniques: Regression, scatter diagram, Normality check, added variable plot, VIF, Residual plots, Index plot, cooks distance plot.\n",
      "Objective: The goal is to build a prediction model to predict the YOGA product of Lenovo based on the given set of variables with good accuracy.\n",
      "Model building Process: \n",
      "Variables were checked for the normality and used scatter plot to detect the correlation between the variables and ran regression equation in R software. Examined the significant variables based on the t test and complimented the t test results with added variable plot and residual plus component plots. Examined the residual plots, Index plot and cook's distance plots. Based on the scatter plot and VIF values identified that there was collinearity existed between two variables. Tried log transformation of one variable and ran the regression again and got satisfactory results and R-square is 83% and adjusted R square was 81%. And built confidence intervals for model coefficients.\n",
      "PROJECT 4:  MARKETING TO FREQUENT CUSTOMERS\n",
      "Tools: R\n",
      "Techniques: Cluster Analysis (hierarchical and K-means clustering)\n",
      "Objective: The goal is to try to identify clusters of customers for Lenovo that have similar characteristics for the purpose of targeting different segments for different types of special offers. \n",
      "Analysis: Applied the hierarchical clustering (Euclidean distance & Ward’s method) and plotted the dendrogram. Identified the 3 cluster- High spending, medium spending and Low spending - with help of dendrogram and compared the results with k-means clustering. By making use of this data, Lenovo can announce various offers to various segments.\n",
      "Education and Certificates\n",
      "M.Tech. (Master of Technology) from Mysore University, Mysore.\n",
      "M.Sc. (Master of Science) in Computer Science from Kuvempu University, Shimoga.\n",
      "B.Sc. (Bachelor of Science) in Computer Science from Kuvempu University, Shimoga.\n",
      "Rewards and Recognition\n",
      "One web implementations-rebranding - Special Recognition Award, 2010.\n",
      "Ecommerce Peer Recognition Award, 2011.\n",
      "Global brand communications – Special Recognition Award, 2012\n",
      "Going Above and Beyond Award, 2013.\n",
      "Global brand communications – Special Recognition Award, 2013.\n",
      "Lenovo.com – Champion Award, 2014.\n",
      "Breakthrough Contribution Award, 2014.\n",
      "Individual Excellence – Enabling Functions, 2015\n",
      "Relevant Skills\n",
      "Outstanding interpersonal and cooperation skills.\n",
      "Excellent presentation and written and oral communication skills.\n",
      "•     Team player and rapid learner with the aptitude to work in a fast paced surroundings.\n",
      "•     Ability to prioritize and run multiple tasks simultaneously.\n",
      "Personal Details\n",
      "Date of Birth\n",
      "31-March-1982\n",
      "Sex\n",
      "Male\n",
      "Marital Status\n",
      "Married\n",
      "Valid Passport\n",
      "Yes\n",
      "I hereby declare that the information given above is true to the best of my knowledge.\n",
      "Date:                                                                 Santhosh Kumar S P\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "path = \"C:\\\\Users\\\\LENOVO\\\\Desktop\\\\res\\\\resumes\\\\\"\n",
    "for filename in os.listdir(path):\n",
    "        if filename.endswith(('.docx')):\n",
    "            print(filename)\n",
    "            for page in extract_text_from_doc(path):\n",
    "                print(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1544684526313_Resume_Akshay_P.docx',\n",
       " 'Abhijeet_Resume_DA (4).docx',\n",
       " 'Asha_Resume.doc',\n",
       " 'Ashis_3yr_Infosys.pdf',\n",
       " 'Ayan_cv_pdf.pdf',\n",
       " 'Copy of Pooja Resume Data_-2019.pdf',\n",
       " 'DilipBehera_Resume.pdf',\n",
       " 'Kuntal RoyChowdhury_Resume.pdf',\n",
       " 'Megha_Resume.pdf',\n",
       " 'Resume (1).docx',\n",
       " 'Rithesh_KV.docx',\n",
       " 'Santhosh Kumar S P.docx',\n",
       " 'Shashikanth Kadam - Data Science   New.pdf',\n",
       " '~$ha_Resume.doc']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#temp = docx2txt.process(path+'Asha_Resume.doc')\n",
    "import os\n",
    "os.getcwd()\n",
    "import comtypes.client\n",
    "word = comtypes.client.CreateObject('Word.Application')\n",
    "path = \"C:\\\\Users\\\\LENOVO\\\\Desktop\\\\res\\\\resumes\\\\\"\n",
    "doc = word.Documents.Open(path+'Asha_Resume.doc') #name of input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\LENOVO\\\\Documents\\\\Danone-MMM-ELN\\\\EDA'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c\n",
    "doc = word.Documents.Open('yesblue.doc') #name of input file\n",
    "doc.SaveAs(out_file, FileFormat=16)  # output file format to Office word Xml default (code=16)\n",
    "doc.Close()\n",
    "word.Quit()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
